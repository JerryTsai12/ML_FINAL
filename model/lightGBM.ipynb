{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "HEmT9VhRK_dF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from time import localtime, strftime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wfCq6h0SA49",
        "outputId": "c389dc8c-65c0-4b58-db81-ba38adb63848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predict_stns: ['500101001', '500101002', '500101003', '500101004', '500101005', '500101006', '500101007', '500101008', '500101009', '500101010', '500101013', '500101014', '500101015', '500101018', '500101019', '500101020', '500101021', '500101022', '500101023', '500101024', '500101025', '500101026', '500101027', '500101028', '500101029', '500101030', '500101031', '500101032', '500101033', '500101034', '500101035', '500101036', '500101037', '500101038', '500101039', '500101040', '500101041', '500101042', '500101091', '500101092', '500101093', '500101094', '500101114', '500101115', '500101123', '500101166', '500101175', '500101176', '500101181', '500101184', '500101185', '500101188', '500101189', '500101190', '500101191', '500101193', '500101199', '500101209', '500101216', '500101219', '500105066', '500106002', '500106003', '500106004', '500119043', '500119044', '500119045', '500119046', '500119047', '500119048', '500119049', '500119050', '500119051', '500119052', '500119053', '500119054', '500119055', '500119056', '500119057', '500119058', '500119059', '500119060', '500119061', '500119062', '500119063', '500119064', '500119065', '500119066', '500119067', '500119068', '500119069', '500119070', '500119071', '500119072', '500119074', '500119075', '500119076', '500119077', '500119078', '500119079', '500119080', '500119081', '500119082', '500119083', '500119084', '500119085', '500119086', '500119087', '500119088', '500119089', '500119090', '500119091']\n"
          ]
        }
      ],
      "source": [
        "with open(\"./data_sno_test_set.txt\", \"r\") as f:\n",
        "    predict_stns = f.read().split()\n",
        "    predict_stns.sort()\n",
        "print(\"predict_stns:\", predict_stns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "BsdGB3ifOg2O"
      },
      "outputs": [],
      "source": [
        "def Err_func(b_predict, b_truth, total):\n",
        "    return 3 * abs(b_predict - b_truth) / total * ( abs((3 * b_truth - total)/(3 *total)) + abs((3 * b_truth - 2 * total)/(3 * total)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "5tC5e_rPOkFh"
      },
      "outputs": [],
      "source": [
        "def val(predic_y, y, total):\n",
        "  err = 0\n",
        "  for i in range(len(y)):\n",
        "    err += Err_func(float(predic_y[i]), y[i], total)\n",
        "\n",
        "  return err / len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "mJscZbxSqTVP"
      },
      "outputs": [],
      "source": [
        "def Load_stn_tot():\n",
        "  with open(\"./data_stn_tot.json\", 'r') as f:\n",
        "    stn_tot = json.load(f)\n",
        "  return dict(stn_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for released days\n",
        "def Load_datelist(mode):\n",
        "    '''\n",
        "    mode`: should be a `str` in `['train', 'val', 'test', 'release']`\\\\\n",
        "    '''\n",
        "    mode_list = ['train', 'val', 'test', 'release']\n",
        "    if mode in mode_list:\n",
        "        with open(f\"data_datelist_{mode}.txt\", 'r') as f:\n",
        "            datelist = f.read().split() \n",
        "        datelist.sort()\n",
        "        return datelist\n",
        "    else:\n",
        "        raise Exception(f'wrong mode, mode should be a `str` in {mode_list}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "1_ZwZr6C_fZS"
      },
      "outputs": [],
      "source": [
        "def read_data(stn, mode):\n",
        "  data = []\n",
        "  x = []\n",
        "  y = []\n",
        "  path = f\"./data/{stn}_{mode}.txt\"\n",
        "\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      tmp_list = line.split()\n",
        "      for i in range(len(tmp_list)):\n",
        "        if i not in [0, 1, 2]:\n",
        "          tmp_list[i] = float(tmp_list[i])\n",
        "      # if tmp_list[1] in week_list:\n",
        "      min = int(tmp_list[2][:2]) * 60 + int(tmp_list[2][3:])\n",
        "      weekday = int(tmp_list[4])\n",
        "      all_min = 1440 * (weekday - 1) + min\n",
        "      if tmp_list[4] == 5 and min > 1440 - 60 * 6:\n",
        "        tmp_list[5] = 0\n",
        "\n",
        "      def sin_a(a, b):\n",
        "        return np.sin(a * 2 * np.pi / b)\n",
        "      def cos_a(a, b):\n",
        "        return np.cos(a * 2 * np.pi / b)\n",
        "      k = 1440\n",
        "      x_input = []\n",
        "      rain = float(tmp_list[7])\n",
        "      # for i in range(1, 7):\n",
        "      #   x_input.append(sin_a(min, k * i))\n",
        "      #   x_input.append(cos_a(min, k * i))\n",
        "      x_input = [sin_a(min, k), cos_a(min, k), sin_a(all_min, k * 7), cos_a(all_min, k * 7)] + tmp_list[5:8]\n",
        "      y_label = int(tmp_list[8])\n",
        "    \n",
        "      \n",
        "      frac = y_label/ tmp_list[3]\n",
        "      # if mode != \"train\":\n",
        "      #   x.append(list(x_input))\n",
        "      #   y.append(y_label)\n",
        "      # elif mode == 'train':\n",
        "      #   N = 5\n",
        "      #   for i in range(int(N * 3 * ( abs(frac - 1/3) + abs(frac - 2/3))) - (N - 1)):\n",
        "      #     x.append(list(x_input))\n",
        "      #     y.append(y_label)\n",
        "      #     if weekday in [6, 7]:\n",
        "      #       for i in range(2):\n",
        "      #         x.append(list(x_input))\n",
        "      #         y.append(y_label)\n",
        "      x.append(list(x_input))\n",
        "      y.append(y_label)\n",
        "          \n",
        "      data.append(tmp_list)\n",
        "      \n",
        "  # print(\"data:\", data)\n",
        "  # print(\"x_train:\", x)\n",
        "  # print(\"y_train:\", y)\n",
        "  data = np.array(data)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  scaler = StandardScaler()\n",
        "  # x = scaler.fit_transform(x)\n",
        "  # y = scaler.transform(y)\n",
        "  return data, x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "f99RZ62fAP6Q"
      },
      "outputs": [],
      "source": [
        "def run(num_leaves, learning_rate, feature_fraction, num_round):\n",
        "  all_val_err = 0\n",
        "  all_train_err = 0\n",
        "  count = 0\n",
        "  stn_tot = Load_stn_tot()\n",
        "  val_json = {}\n",
        "\n",
        "  predict_file = open(f\"./lightGBM_predict_{strftime('%m%d-%H-%M-%S', localtime())}.csv\", 'w')\n",
        "  predict_file.write(\"id,sbi\\n\")\n",
        "\n",
        "  predict_log_file = open(f\"./lightGBM_predict_log_{strftime('%m%d-%H-%M-%S', localtime())}.txt\", \"w\")\n",
        "  print(f\"date_val: {Load_datelist('val')}\")\n",
        "  print(f\"date_val: {Load_datelist('val')}\", file=predict_log_file)\n",
        "  print(f\"date_train: {Load_datelist('train')}\")\n",
        "  print(f\"date_train: {Load_datelist('train')}\", file=predict_log_file)\n",
        "  print(f\"date_train: {Load_datelist('test')}\")\n",
        "  print(f\"date_train: {Load_datelist('test')}\", file=predict_log_file)\n",
        "\n",
        "  # predict_stns = ['500101001']\n",
        "  for stn in predict_stns:\n",
        "    count += 1\n",
        "    data_train, x_train, y_train = read_data(stn, 'train')\n",
        "    data_val, x_val, y_val = read_data(stn, 'val')\n",
        "    data_test, x_test, y_test = read_data(stn, 'test')\n",
        "\n",
        "    train_data = lgb.Dataset(x_train, label=y_train)\n",
        "    val_data = lgb.Dataset(x_val, label=y_val, reference=train_data)\n",
        "    params = {\n",
        "      'objective': 'regression',\n",
        "      'metric': 'mse',\n",
        "      'boosting_type': 'gbdt',\n",
        "      'num_leaves': num_leaves,\n",
        "      'learning_rate': learning_rate,\n",
        "      'feature_fraction': feature_fraction,\n",
        "      'verbose' : -1,\n",
        "    }\n",
        "\n",
        "    # Train the model\n",
        "    \n",
        "    model = lgb.train(params, train_data, num_round, valid_sets=[val_data])\n",
        "    pre_train = model.predict(x_train)\n",
        "\n",
        "    pre_val = model.predict(x_val)\n",
        "    train_err = val(pre_train, y_train, int(stn_tot[stn]))\n",
        "    val_err = val(pre_val, y_val, int(stn_tot[stn]))\n",
        "    all_train_err += train_err\n",
        "    all_val_err += val_err\n",
        "    \n",
        "    log_info = f\"{stn}: train: {train_err:<19}, \\033[34mval: {val_err:<19}\\033[0m, avg_train: {all_train_err / count:<19}, avg_val: {all_val_err/count:<19}\"\n",
        "    print(log_info, file=predict_log_file)\n",
        "    print(log_info)\n",
        "    \n",
        "    val_json[stn] = {}\n",
        "    val_json[stn]['val'] = val_err\n",
        "    val_json[stn]['train'] = train_err\n",
        "    \n",
        "    \n",
        "    # plt.figure(figsize=(80, 5), dpi=300)\n",
        "    # plt.plot(pre_train, label='pre_train', color='b')\n",
        "    # plt.plot(y_train, label='truth', color='darkorange')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    \n",
        "    # plt.figure(figsize=(80, 5), dpi=300)\n",
        "    # plt.plot(pre_val, label='pre_train', color='b')\n",
        "    # plt.plot(y_val, label='truth', color='darkorange')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    # if all_val_err/count > 0.38:\n",
        "    #   return all_val_err/count\n",
        "    pre_test = model.predict(x_test)\n",
        "    for i in range(len(data_test)):\n",
        "      if data_test[i][2][3:] in [\"00\", \"20\", \"40\"]:\n",
        "        pre_test[i] = pre_test[i] if pre_test[i] > 0 else 0\n",
        "        id = f'{data_test[i][1]}_{int(data_test[i][0])}_{data_test[i][2]}'\n",
        "        predict_file.write(f\"{id},{pre_test[i]}\\n\")\n",
        "        \n",
        "  log_info = f\"final: train: {all_train_err / len(predict_stns)}, val: {all_val_err / len(predict_stns)}\"\n",
        "  print(log_info, file=predict_log_file)\n",
        "  print(log_info)\n",
        "\n",
        "  predict_file.close()\n",
        "  predict_log_file.close()\n",
        "  with open(\"./val_lightGBM.json\", 'w') as f: \n",
        "    json.dump(val_json, f, indent=2)\n",
        "  return all_val_err / len(predict_stns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a = []\n",
        "# b = []\n",
        "\n",
        "# for num_leaves in [16, 31, 64]:\n",
        "#     for feature_fraction in [0.5, 0.7, 0.9]:\n",
        "#         for learning_rate in [0.03, 0.05, 0.07, 0.09]:\n",
        "#             for num_round in [10, 25, 50, 75]:\n",
        "#                 print(num_leaves, feature_fraction, learning_rate, num_round)\n",
        "#                 a.append(run(num_leaves, learning_rate, feature_fraction, num_round))\n",
        "#                 b.append((num_leaves, feature_fraction, learning_rate, num_round))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_val: ['20231123', '20231124', '20231125', '20231126', '20231127', '20231128', '20231129']\n",
            "date_train: ['20231002', '20231003', '20231004', '20231005', '20231006', '20231007', '20231008', '20231009', '20231010', '20231011', '20231016', '20231017', '20231018', '20231019', '20231020', '20231025', '20231026', '20231027', '20231028', '20231029', '20231030', '20231031', '20231101', '20231102', '20231103', '20231104', '20231105', '20231106', '20231107', '20231108', '20231109', '20231110', '20231111', '20231112', '20231113', '20231114', '20231115', '20231116', '20231117', '20231118', '20231119', '20231120', '20231121', '20231122', '20231201', '20231202', '20231203', '20231204', '20231205', '20231206', '20231207', '20231208', '20231209', '20231210', '20231211', '20231212', '20231213']\n",
            "date_train: ['20231021', '20231022', '20231023', '20231024', '20231218', '20231219', '20231220', '20231221', '20231222', '20231223', '20231224']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500101001: train: 0.22553751073578746, \u001b[34mval: 0.27628344005893585\u001b[0m, avg_train: 0.22553751073578746, avg_val: 0.27628344005893585\n",
            "500101002: train: 0.21884808109809037, \u001b[34mval: 0.2452154427658377 \u001b[0m, avg_train: 0.2221927959169389 , avg_val: 0.26074944141238676\n",
            "500101003: train: 0.3502465321037816 , \u001b[34mval: 0.395156934227986  \u001b[0m, avg_train: 0.2648773746458865 , avg_val: 0.3055519390175865 \n",
            "500101004: train: 0.32946907586364105, \u001b[34mval: 0.4720350178041393 \u001b[0m, avg_train: 0.2810252999503251 , avg_val: 0.3471727087142247 \n",
            "500101005: train: 0.26383585712156715, \u001b[34mval: 0.3183261413467233 \u001b[0m, avg_train: 0.2775874113845735 , avg_val: 0.3414033952407244 \n",
            "500101006: train: 0.2733294391541744 , \u001b[34mval: 0.3833709487946007 \u001b[0m, avg_train: 0.27687774934617365, avg_val: 0.3483979874997038 \n",
            "500101007: train: 0.26144461573356376, \u001b[34mval: 0.35595938091135104\u001b[0m, avg_train: 0.2746730159729437 , avg_val: 0.3494781865585105 \n",
            "500101008: train: 0.44590286481962643, \u001b[34mval: 0.5068690039413482 \u001b[0m, avg_train: 0.296076747078779  , avg_val: 0.3691520387313652 \n",
            "500101009: train: 0.3842995400016358 , \u001b[34mval: 0.3895757843640935 \u001b[0m, avg_train: 0.3058792796257631 , avg_val: 0.37142134380166836\n",
            "500101010: train: 0.36927336557747237, \u001b[34mval: 0.5023604184423555 \u001b[0m, avg_train: 0.312218688220934  , avg_val: 0.38451525126573705\n",
            "500101013: train: 0.34669489774198164, \u001b[34mval: 0.5093777796997662 \u001b[0m, avg_train: 0.3153528890864838 , avg_val: 0.3958663902142851 \n",
            "500101014: train: 0.3967590417707352 , \u001b[34mval: 0.4317200028153703 \u001b[0m, avg_train: 0.32213673514350477, avg_val: 0.39885419126437555\n",
            "500101015: train: 0.2728573664156646 , \u001b[34mval: 0.3916841131508325 \u001b[0m, avg_train: 0.31834601447213245, avg_val: 0.398302646794103  \n",
            "500101018: train: 0.471324089148122  , \u001b[34mval: 0.5827831907082457 \u001b[0m, avg_train: 0.32927301980613166, avg_val: 0.41147982850225606\n",
            "500101019: train: 0.30830276888977787, \u001b[34mval: 0.3312824122797765 \u001b[0m, avg_train: 0.32787500307837475, avg_val: 0.4061333340874241 \n",
            "500101020: train: 0.0                , \u001b[34mval: 0.0                \u001b[0m, avg_train: 0.30738281538597634, avg_val: 0.3807500007069601 \n",
            "500101021: train: 0.350275678025666  , \u001b[34mval: 0.3655497187357822 \u001b[0m, avg_train: 0.3099059249530169 , avg_val: 0.3798558664733614 \n",
            "500101022: train: 0.19667634765121028, \u001b[34mval: 0.22268864035071495\u001b[0m, avg_train: 0.3036153928806943 , avg_val: 0.3711243539109922 \n",
            "500101023: train: 0.29440371989002545, \u001b[34mval: 0.3355077232823757 \u001b[0m, avg_train: 0.3031305679864486 , avg_val: 0.3692497944042229 \n",
            "500101024: train: 0.1759649327311648 , \u001b[34mval: 0.2154988506962754 \u001b[0m, avg_train: 0.2967722862236844 , avg_val: 0.3615622472188255 \n",
            "500101025: train: 0.15652907384590775, \u001b[34mval: 0.17465778322991576\u001b[0m, avg_train: 0.2900940380152188 , avg_val: 0.35266203464792506\n",
            "500101026: train: 0.37981430173952574, \u001b[34mval: 0.42099858019907943\u001b[0m, avg_train: 0.29417223182086916, avg_val: 0.35576824126388656\n",
            "500101027: train: 0.2892259513711513 , \u001b[34mval: 0.3416456315445902 \u001b[0m, avg_train: 0.2939571761491423 , avg_val: 0.355154214754352  \n",
            "500101028: train: 0.2982555245328013 , \u001b[34mval: 0.37213103512984796\u001b[0m, avg_train: 0.29413627399846143, avg_val: 0.3558615822699977 \n",
            "500101029: train: 0.26024258205168654, \u001b[34mval: 0.2588624963988336 \u001b[0m, avg_train: 0.29278052632059043, avg_val: 0.3519816188351511 \n",
            "500101030: train: 0.21751504573710134, \u001b[34mval: 0.2642624698122248 \u001b[0m, avg_train: 0.2898857001443024 , avg_val: 0.3486078054111924 \n",
            "500101031: train: 0.28653184437080564, \u001b[34mval: 0.3552268503676388 \u001b[0m, avg_train: 0.2897614832638025 , avg_val: 0.3488529552243942 \n",
            "500101032: train: 0.16456751835389094, \u001b[34mval: 0.16038060405879728\u001b[0m, avg_train: 0.2852902702313057 , avg_val: 0.34212179982562285\n",
            "500101033: train: 0.18136579539188025, \u001b[34mval: 0.2579456944943586 \u001b[0m, avg_train: 0.28170666765063584, avg_val: 0.3392191755038551 \n",
            "500101034: train: 0.18868801866721846, \u001b[34mval: 0.2516982261935464 \u001b[0m, avg_train: 0.27860604601785527, avg_val: 0.3363018105268448 \n",
            "500101035: train: 0.19238563675391313, \u001b[34mval: 0.25956927680900754\u001b[0m, avg_train: 0.275824742493212  , avg_val: 0.3338265675036888 \n",
            "500101036: train: 0.19993203551019575, \u001b[34mval: 0.19408406796301103\u001b[0m, avg_train: 0.27345309539999274, avg_val: 0.3294596143930426 \n",
            "500101037: train: 0.26186134478762896, \u001b[34mval: 0.2495212859640074 \u001b[0m, avg_train: 0.2731018302299211 , avg_val: 0.327037240804284  \n",
            "500101038: train: 0.19786333634156553, \u001b[34mval: 0.20010300137918138\u001b[0m, avg_train: 0.27088893335085185, avg_val: 0.3233038808211927 \n",
            "500101039: train: 0.2838126974693462 , \u001b[34mval: 0.3131624318356265 \u001b[0m, avg_train: 0.2712581837542374 , avg_val: 0.32301412513589084\n",
            "500101040: train: 0.32676312132454743, \u001b[34mval: 0.3569279092173792 \u001b[0m, avg_train: 0.2727999875756349 , avg_val: 0.32395617469370996\n",
            "500101041: train: 0.25953270904130793, \u001b[34mval: 0.21904305397270638\u001b[0m, avg_train: 0.27244141248011255, avg_val: 0.32112068494449364\n",
            "500101042: train: 0.25640929239972016, \u001b[34mval: 0.2938796148283364 \u001b[0m, avg_train: 0.2720195145832601 , avg_val: 0.320403814678279  \n",
            "500101091: train: 0.2592106524034488 , \u001b[34mval: 0.3153439264293382 \u001b[0m, avg_train: 0.2716910822196752 , avg_val: 0.3202740739539472 \n",
            "500101092: train: 0.2332010812270213 , \u001b[34mval: 0.38189287936804533\u001b[0m, avg_train: 0.2707288321948588 , avg_val: 0.32181454408929966\n",
            "500101093: train: 0.23481029748399776, \u001b[34mval: 0.32639194692753287\u001b[0m, avg_train: 0.2698527703726427 , avg_val: 0.3219261880609639 \n",
            "500101094: train: 0.2631415931769454 , \u001b[34mval: 0.2782620875006136 \u001b[0m, avg_train: 0.2696929804394118 , avg_val: 0.32088656661905074\n",
            "500101114: train: 0.29543172053375555, \u001b[34mval: 0.289114377399611  \u001b[0m, avg_train: 0.27029155579044306, avg_val: 0.32014767849766845\n",
            "500101115: train: 0.25547207296439567, \u001b[34mval: 0.30398818017447377\u001b[0m, avg_train: 0.2699547493625784 , avg_val: 0.3197804171721413 \n",
            "500101123: train: 0.20746788036211428, \u001b[34mval: 0.22680868894170367\u001b[0m, avg_train: 0.2685661522736792 , avg_val: 0.31771437876702047\n",
            "500101166: train: 0.18721314217640142, \u001b[34mval: 0.3161743887562262 \u001b[0m, avg_train: 0.2667976085759123 , avg_val: 0.3176809007233075 \n",
            "500101175: train: 0.29625835975449355, \u001b[34mval: 0.3398747299388641 \u001b[0m, avg_train: 0.2674244330690736 , avg_val: 0.31815310985555345\n",
            "500101176: train: 0.21300001653385703, \u001b[34mval: 0.26876667563676604\u001b[0m, avg_train: 0.26629059105792324, avg_val: 0.3171242258093287 \n",
            "500101181: train: 0.2786354815387209 , \u001b[34mval: 0.3314631148113065 \u001b[0m, avg_train: 0.26654252759834773, avg_val: 0.3174168561971241 \n",
            "500101184: train: 0.30497852157467675, \u001b[34mval: 0.32808471932335975\u001b[0m, avg_train: 0.26731124747787427, avg_val: 0.31763021345964887\n",
            "500101185: train: 0.35138976808408384, \u001b[34mval: 0.5065417041441075 \u001b[0m, avg_train: 0.2689598459211333 , avg_val: 0.32133436033581475\n",
            "500101188: train: 0.18771368246035552, \u001b[34mval: 0.3162163251590442 \u001b[0m, avg_train: 0.2673974197007337 , avg_val: 0.3212359365824153 \n",
            "500101189: train: 0.3967931214862109 , \u001b[34mval: 0.454185361220177  \u001b[0m, avg_train: 0.26983884803630875, avg_val: 0.32374441629256173\n",
            "500101190: train: 0.2538491641117294 , \u001b[34mval: 0.27132427543487664\u001b[0m, avg_train: 0.2695427427784462 , avg_val: 0.32277367294334536\n",
            "500101191: train: 0.21962786772071116, \u001b[34mval: 0.27626637626793865\u001b[0m, avg_train: 0.26863519959557824, avg_val: 0.32192808573106524\n",
            "500101193: train: 0.22349670636577032, \u001b[34mval: 0.19345524366970945\u001b[0m, avg_train: 0.26782915507361743, avg_val: 0.3196339278371125 \n",
            "500101199: train: 0.32693436830090045, \u001b[34mval: 0.35628167841559444\u001b[0m, avg_train: 0.26886608863900835, avg_val: 0.3202768708297174 \n",
            "500101209: train: 0.21677142581308587, \u001b[34mval: 0.21292304354692695\u001b[0m, avg_train: 0.2679679047971821 , avg_val: 0.3184259427731176 \n",
            "500101216: train: 0.30269472436386635, \u001b[34mval: 0.3435083466775004 \u001b[0m, avg_train: 0.26855649495932926, avg_val: 0.31885106826302234\n",
            "500101219: train: 0.33284636827982905, \u001b[34mval: 0.2923177234226627 \u001b[0m, avg_train: 0.26962799284800426, avg_val: 0.31840884584901635\n",
            "500105066: train: 0.32359801795480586, \u001b[34mval: 0.46706146880455846\u001b[0m, avg_train: 0.2705127473579518 , avg_val: 0.3208457740941892 \n",
            "500106002: train: 0.2620481523888505 , \u001b[34mval: 0.33558803250220276\u001b[0m, avg_train: 0.2703762216326437 , avg_val: 0.3210835524556087 \n",
            "500106003: train: 0.2379122659087478 , \u001b[34mval: 0.26653914658279954\u001b[0m, avg_train: 0.2698609207481374 , avg_val: 0.32021776823540543\n",
            "500106004: train: 0.31614290821071817, \u001b[34mval: 0.4336684543768198 \u001b[0m, avg_train: 0.2705840768022402 , avg_val: 0.32199043520636506\n",
            "500119043: train: 0.15676702359508213, \u001b[34mval: 0.18238989032431258\u001b[0m, avg_train: 0.2688330452144378 , avg_val: 0.3198427345158719 \n",
            "500119044: train: 0.28340604294435245, \u001b[34mval: 0.3540239279494968 \u001b[0m, avg_train: 0.2690538482103456 , avg_val: 0.3203606313860784 \n",
            "500119045: train: 0.2785974518509901 , \u001b[34mval: 0.35364246130245464\u001b[0m, avg_train: 0.2691962900557284 , avg_val: 0.32085737511617357\n",
            "500119046: train: 0.26187465400159377, \u001b[34mval: 0.25755544691245164\u001b[0m, avg_train: 0.26908861893728525, avg_val: 0.3199264644072953 \n",
            "500119047: train: 0.24481025276004012, \u001b[34mval: 0.27700583153532354\u001b[0m, avg_train: 0.2687367585579049 , avg_val: 0.3193044262497305 \n",
            "500119048: train: 0.22471477671869178, \u001b[34mval: 0.22207453776158206\u001b[0m, avg_train: 0.268107873103059  , avg_val: 0.31791542784275695\n",
            "500119049: train: 0.17361139110519158, \u001b[34mval: 0.2160684651380358 \u001b[0m, avg_train: 0.26677693673689185, avg_val: 0.31648096357931016\n",
            "500119050: train: 0.25365424466505226, \u001b[34mval: 0.30908633925422796\u001b[0m, avg_train: 0.26659467712478296, avg_val: 0.316378260463684  \n",
            "500119051: train: 0.1501397306544271 , \u001b[34mval: 0.2195790818121817 \u001b[0m, avg_train: 0.264999403885463  , avg_val: 0.315052244317773  \n",
            "500119052: train: 0.27713684733425203, \u001b[34mval: 0.3460005953505392 \u001b[0m, avg_train: 0.2651634233915277 , avg_val: 0.31547046527767525\n",
            "500119053: train: 0.26822170930304534, \u001b[34mval: 0.33149938164249926\u001b[0m, avg_train: 0.2652042005370146 , avg_val: 0.31568418416253957\n",
            "500119054: train: 0.2068694948759237 , \u001b[34mval: 0.26065088040613577\u001b[0m, avg_train: 0.2644366386204213 , avg_val: 0.31496006174469215\n",
            "500119055: train: 0.3364931955131595 , \u001b[34mval: 0.4699851432378154 \u001b[0m, avg_train: 0.26537243806058675, avg_val: 0.3169733744913561 \n",
            "500119056: train: 0.28053900194035686, \u001b[34mval: 0.2444574299114975 \u001b[0m, avg_train: 0.2655668811872505 , avg_val: 0.31604368289417845\n",
            "500119057: train: 0.29383236921623596, \u001b[34mval: 0.2783662489371597 \u001b[0m, avg_train: 0.2659246721749592 , avg_val: 0.3155667533504187 \n",
            "500119058: train: 0.2708755121791953 , \u001b[34mval: 0.35722140917830375\u001b[0m, avg_train: 0.2659865576750121 , avg_val: 0.31608743654826726\n",
            "500119059: train: 0.168387589473142  , \u001b[34mval: 0.1605860465244052 \u001b[0m, avg_train: 0.26478163214165573, avg_val: 0.3141676663010591 \n",
            "500119060: train: 0.28711263854450647, \u001b[34mval: 0.31385746345404497\u001b[0m, avg_train: 0.26505396148803195, avg_val: 0.3141638833395101 \n",
            "500119061: train: 0.33423801869748204, \u001b[34mval: 0.42570390400494085\u001b[0m, avg_train: 0.26588750434597713, avg_val: 0.315507739010178  \n",
            "500119062: train: 0.23643866345976172, \u001b[34mval: 0.3147453019796639 \u001b[0m, avg_train: 0.26553692290685554, avg_val: 0.3154986623788623 \n",
            "500119063: train: 0.24802442631417743, \u001b[34mval: 0.2924277980488763 \u001b[0m, avg_train: 0.26533089353517697, avg_val: 0.3152272404455684 \n",
            "500119064: train: 0.1747561417570645 , \u001b[34mval: 0.19043624934981362\u001b[0m, avg_train: 0.26427769874705936, avg_val: 0.3137761824095712 \n",
            "500119065: train: 0.2807351339207545 , \u001b[34mval: 0.34092646365540186\u001b[0m, avg_train: 0.2644668646685961 , avg_val: 0.31408825460779916\n",
            "500119066: train: 0.24057264056788874, \u001b[34mval: 0.2893258906494284 \u001b[0m, avg_train: 0.2641953393947244 , avg_val: 0.31380686410827224\n",
            "500119067: train: 0.18020341194845813, \u001b[34mval: 0.21640783997195753\u001b[0m, avg_train: 0.26325160987285623, avg_val: 0.3127124930505608 \n",
            "500119068: train: 0.18624128092900763, \u001b[34mval: 0.2121933577617788 \u001b[0m, avg_train: 0.2623959395512579 , avg_val: 0.3115956137695744 \n",
            "500119069: train: 0.26736894437676834, \u001b[34mval: 0.3441731646236708 \u001b[0m, avg_train: 0.2624505879559339 , avg_val: 0.3119536088339051 \n",
            "500119070: train: 0.3634507185993189 , \u001b[34mval: 0.34795726206374283\u001b[0m, avg_train: 0.2635484154629272 , avg_val: 0.3123449528907512 \n",
            "500119071: train: 0.23933176582130875, \u001b[34mval: 0.2706792823423823 \u001b[0m, avg_train: 0.26328802138075924, avg_val: 0.3118969349278655 \n",
            "500119072: train: 0.3072549305489332 , \u001b[34mval: 0.3720629245096542 \u001b[0m, avg_train: 0.2637557544570164 , avg_val: 0.3125369986468207 \n",
            "500119074: train: 0.2784091938163088 , \u001b[34mval: 0.2877958498420286 \u001b[0m, avg_train: 0.2639100011871142 , avg_val: 0.31227656550150706\n",
            "500119075: train: 0.20128745564912615, \u001b[34mval: 0.22695595762720522\u001b[0m, avg_train: 0.2632576830044268 , avg_val: 0.3113878091694831 \n",
            "500119076: train: 0.19010513874463222, \u001b[34mval: 0.21087884271355975\u001b[0m, avg_train: 0.2625035330636042 , avg_val: 0.31035163425756634\n",
            "500119077: train: 0.26619843404779076, \u001b[34mval: 0.3445356676438008 \u001b[0m, avg_train: 0.2625412361348714 , avg_val: 0.31070045092477283\n",
            "500119078: train: 0.4133101133650136 , \u001b[34mval: 0.38489056903156443\u001b[0m, avg_train: 0.26406415408669104, avg_val: 0.31144984605716464\n",
            "500119079: train: 0.39795037092707874, \u001b[34mval: 0.4362394283234928 \u001b[0m, avg_train: 0.2654030162550949 , avg_val: 0.31269774187982796\n",
            "500119080: train: 0.27313861433854075, \u001b[34mval: 0.28899477442120436\u001b[0m, avg_train: 0.265479606335129  , avg_val: 0.312463059033703  \n",
            "500119081: train: 0.26646673381742275, \u001b[34mval: 0.3306780315833204 \u001b[0m, avg_train: 0.2654892840555437 , avg_val: 0.3126416371959541 \n",
            "500119082: train: 0.37806631366729804, \u001b[34mval: 0.3339314272747296 \u001b[0m, avg_train: 0.2665822649255607 , avg_val: 0.3128483341870102 \n",
            "500119083: train: 0.26467732765462426, \u001b[34mval: 0.250764705603925  \u001b[0m, avg_train: 0.26656394822103247, avg_val: 0.31225137621986515\n",
            "500119084: train: 0.25392178604549015, \u001b[34mval: 0.3107349124206174 \u001b[0m, avg_train: 0.2664435466765035 , avg_val: 0.3122369337074914 \n",
            "500119085: train: 0.2812778556212548 , \u001b[34mval: 0.3070851350058493 \u001b[0m, avg_train: 0.26658349298730305, avg_val: 0.3121883318329476 \n",
            "500119086: train: 0.24362943969038034, \u001b[34mval: 0.23641326132843457\u001b[0m, avg_train: 0.26636896912471497, avg_val: 0.3114801536039335 \n",
            "500119087: train: 0.24382322147766142, \u001b[34mval: 0.285089871709162  \u001b[0m, avg_train: 0.2661602122020571 , avg_val: 0.3112357991419448 \n",
            "500119088: train: 0.2587088079322609 , \u001b[34mval: 0.3385182414805955 \u001b[0m, avg_train: 0.26609185069499475, avg_val: 0.3114860967780792 \n",
            "500119089: train: 0.2006078869699035 , \u001b[34mval: 0.22232379144449077\u001b[0m, avg_train: 0.2654965419338575 , avg_val: 0.3106755303659557 \n",
            "500119090: train: 0.24996036438467048, \u001b[34mval: 0.29676758384494956\u001b[0m, avg_train: 0.2653565763703513 , avg_val: 0.3105502335504511 \n",
            "500119091: train: 0.2919419261249178 , \u001b[34mval: 0.31126510272296387\u001b[0m, avg_train: 0.26559394556458854, avg_val: 0.31055661631091996\n",
            "final: train: 0.26559394556458854, val: 0.31055661631091996\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.31055661631091996"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run(num_leaves=31, learning_rate=0.05, feature_fraction=0.9, num_round=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
