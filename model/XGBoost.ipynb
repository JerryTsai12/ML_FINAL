{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HEmT9VhRK_dF"
      },
      "outputs": [],
      "source": [
        "# import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import random as rd\n",
        "from tqdm import tqdm\n",
        "from itertools import *\n",
        "from scipy.stats import uniform, randint\n",
        "import math\n",
        "import json\n",
        "# import tensorflow\n",
        "# from tenserflow.keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from pmdarima import auto_arima\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import LSTM, Dense\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wfCq6h0SA49",
        "outputId": "c389dc8c-65c0-4b58-db81-ba38adb63848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predict_stns: ['500101001', '500101002', '500101003', '500101004', '500101005', '500101006', '500101007', '500101008', '500101009', '500101010', '500101013', '500101014', '500101015', '500101018', '500101019', '500101020', '500101021', '500101022', '500101023', '500101024', '500101025', '500101026', '500101027', '500101028', '500101029', '500101030', '500101031', '500101032', '500101033', '500101034', '500101035', '500101036', '500101037', '500101038', '500101039', '500101040', '500101041', '500101042', '500101091', '500101092', '500101093', '500101094', '500101114', '500101115', '500101123', '500101166', '500101175', '500101176', '500101181', '500101184', '500101185', '500101188', '500101189', '500101190', '500101191', '500101193', '500101199', '500101209', '500101216', '500101219', '500105066', '500106002', '500106003', '500106004', '500119043', '500119044', '500119045', '500119046', '500119047', '500119048', '500119049', '500119050', '500119051', '500119052', '500119053', '500119054', '500119055', '500119056', '500119057', '500119058', '500119059', '500119060', '500119061', '500119062', '500119063', '500119064', '500119065', '500119066', '500119067', '500119068', '500119069', '500119070', '500119071', '500119072', '500119074', '500119075', '500119076', '500119077', '500119078', '500119079', '500119080', '500119081', '500119082', '500119083', '500119084', '500119085', '500119086', '500119087', '500119088', '500119089', '500119090', '500119091']\n"
          ]
        }
      ],
      "source": [
        "with open(\"./data_sno_test_set.txt\", \"r\") as f:\n",
        "    predict_stns = f.read().split()\n",
        "    predict_stns.sort()\n",
        "print(\"predict_stns:\", predict_stns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1_ZwZr6C_fZS"
      },
      "outputs": [],
      "source": [
        "def read_data(stn, mode):\n",
        "  data = []\n",
        "  x = []\n",
        "  y = []\n",
        "  path = f\"./data/{stn}_{mode}.txt\"\n",
        "\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      tmp_list = line.split()\n",
        "      for i in range(len(tmp_list)):\n",
        "        if i not in [0, 1, 2]:\n",
        "          tmp_list[i] = float(tmp_list[i])\n",
        "      # if tmp_list[1] in week_list:\n",
        "      min = int(tmp_list[2][:2]) * 60 + int(tmp_list[2][3:])\n",
        "      weekday = int(tmp_list[4])\n",
        "      all_min = 1440 * (weekday - 1) + min\n",
        "      if tmp_list[4] == 5 and min > 1440 - 60 * 6:\n",
        "        tmp_list[5] = 0\n",
        "\n",
        "      def sin_a(a, b):\n",
        "        return np.sin(a * 2 * np.pi / b)\n",
        "      def cos_a(a, b):\n",
        "        return np.cos(a * 2 * np.pi / b)\n",
        "      k = 1440\n",
        "      x_input = []\n",
        "      rain = float(tmp_list[7])\n",
        "      # for i in range(1, 7):\n",
        "      #   x_input.append(sin_a(min, k * i))\n",
        "      #   x_input.append(cos_a(min, k * i))\n",
        "      x_input = [sin_a(min, k), cos_a(min, k), sin_a(all_min, k * 7), cos_a(all_min, k * 7)] + tmp_list[5:8]\n",
        "      y_label = int(tmp_list[8])\n",
        "    \n",
        "      \n",
        "      frac = y_label/ tmp_list[3]\n",
        "      if mode != \"train\":\n",
        "        x.append(list(x_input))\n",
        "        y.append(y_label)\n",
        "      elif mode == 'train':\n",
        "        N = 10\n",
        "        for i in range(int(N * 3 * ( abs(frac - 1/3) + abs(frac - 2/3))) - (N - 1)):\n",
        "          x.append(list(x_input))\n",
        "          y.append(y_label)\n",
        "          # if weekday in [6, 7]:\n",
        "          #   for i in range(2):\n",
        "          #     x.append(list(x_input))\n",
        "          #     y.append(y_label)\n",
        "      # x.append(list(x_input))\n",
        "      # y.append(y_label)\n",
        "          \n",
        "      data.append(tmp_list)\n",
        "      \n",
        "  # print(\"data:\", data)\n",
        "  # print(\"x_train:\", x)\n",
        "  # print(\"y_train:\", y)\n",
        "  data = np.array(data)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  scaler = StandardScaler()\n",
        "  # x = scaler.fit_transform(x)\n",
        "  # y = scaler.transform(y)\n",
        "  return data, x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BsdGB3ifOg2O"
      },
      "outputs": [],
      "source": [
        "def Err_func(b_predict, b_truth, total):\n",
        "    return 3 * abs(b_predict - b_truth) / total * ( abs((3 * b_truth - total)/(3 *total)) + abs((3 * b_truth - 2 * total)/(3 * total)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5tC5e_rPOkFh"
      },
      "outputs": [],
      "source": [
        "def val(predic_y, y, total):\n",
        "  err = 0\n",
        "  for i in range(len(y)):\n",
        "    predic_y[i] = predic_y[i] if predic_y[i] > 0 else 0 \n",
        "    err += Err_func(float(predic_y[i]), y[i], total)\n",
        "\n",
        "  return err / len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mJscZbxSqTVP"
      },
      "outputs": [],
      "source": [
        "def Load_stn_tot():\n",
        "  with open(\"./data_stn_tot.json\", 'r') as f:\n",
        "    stn_tot = json.load(f)\n",
        "  return dict(stn_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "f99RZ62fAP6Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500101001: train: 0.17380887224570785, \u001b[34mval: 0.27525109860565405\u001b[0m, avg_train: 0.17380887224570785, avg_val: 0.27525109860565405\n",
            "500101002: train: 0.15396302760789574, \u001b[34mval: 0.2261597900649796 \u001b[0m, avg_train: 0.16388594992680178, avg_val: 0.25070544433531683\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m data_test, x_test, y_test \u001b[38;5;241m=\u001b[39m read_data(stn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, min_child_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m pre_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_train)\n\u001b[1;32m     20\u001b[0m pre_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_val)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/xgboost/sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m (\n\u001b[1;32m   1078\u001b[0m     model,\n\u001b[1;32m   1079\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1085\u001b[0m )\n\u001b[0;32m-> 1086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2049\u001b[0m     _check_call(\n\u001b[0;32m-> 2050\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2053\u001b[0m     )\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2055\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "all_val_err = 0\n",
        "all_train_err = 0\n",
        "count = 0\n",
        "predict_file = open(\"./XGboost_predict.csv\", 'w')\n",
        "predict_file.write(\"id,sbi\\n\")\n",
        "stn_tot = Load_stn_tot()\n",
        "val_xgb = {}\n",
        "# predict_stns = ['500101001']\n",
        "for stn in predict_stns:\n",
        "  count += 1\n",
        "  data_train, x_train, y_train = read_data(stn, 'train')\n",
        "  data_val, x_val, y_val = read_data(stn, 'val')\n",
        "  data_test, x_test, y_test = read_data(stn, 'test')\n",
        "\n",
        "\n",
        "  model = XGBRegressor(n_estimators=100, learning_rate= 0.3, max_depth=6, min_child_weight=1)\n",
        "  model.fit(x_train, y_train)\n",
        "  pre_train = model.predict(x_train)\n",
        "\n",
        "  pre_val = model.predict(x_val)\n",
        "  train_err = val(pre_train, y_train, int(stn_tot[stn]))\n",
        "  val_err = val(pre_val, y_val, int(stn_tot[stn]))\n",
        "  all_train_err += train_err\n",
        "  all_val_err += val_err\n",
        "  print(f\"{stn}: train: {train_err:<19}, \\033[34mval: {val_err:<19}\\033[0m, avg_train: {all_train_err / count:<19}, avg_val: {all_val_err/count:<19}\")\n",
        "  \n",
        "  # plt.figure(figsize=(80, 5), dpi=300)\n",
        "  # plt.plot(pre_train, label='pre_train', color='b')\n",
        "  # plt.plot(y_train, label='truth', color='darkorange')\n",
        "  # plt.legend()\n",
        "  # plt.show()\n",
        "  \n",
        "  # plt.figure(figsize=(80, 5), dpi=300)\n",
        "  # plt.plot(pre_val, label='pre_train', color='b')\n",
        "  # plt.plot(y_val, label='truth', color='darkorange')\n",
        "  # plt.legend()\n",
        "  # plt.show()\n",
        "  \n",
        "  pre_test = model.predict(x_test)\n",
        "  for i in range(len(data_test)):\n",
        "    if data_test[i][2][3:] in [\"00\", \"20\", \"40\"]:\n",
        "      pre_test[i] = pre_test[i] if pre_test[i] > 0 else 0\n",
        "      id = f'{data_test[i][1]}_{int(data_test[i][0])}_{data_test[i][2]}'\n",
        "      predict_file.write(f\"{id},{pre_test[i]}\\n\")\n",
        "      \n",
        "  val_xgb[stn] = {}\n",
        "  val_xgb[stn]['val'] = val_err\n",
        "  val_xgb[stn]['tarin'] = train_err\n",
        "\n",
        "predict_file.close()\n",
        "print(f\"final: train: {all_train_err / len(predict_stns)}, val: {all_val_err / len(predict_stns)}\")\n",
        "with open(\"./val_XGBoost.json\", 'w') as f:\n",
        "  json.dump(val_xgb, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
