{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HEmT9VhRK_dF"
      },
      "outputs": [],
      "source": [
        "# import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import random as rd\n",
        "from tqdm import tqdm\n",
        "from itertools import *\n",
        "from scipy.stats import uniform, randint\n",
        "import math\n",
        "import json\n",
        "# import tensorflow\n",
        "# from tenserflow.keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from pmdarima import auto_arima\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import LSTM, Dense\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wfCq6h0SA49",
        "outputId": "c389dc8c-65c0-4b58-db81-ba38adb63848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predict_stns: ['500101001', '500101002', '500101003', '500101004', '500101005', '500101006', '500101007', '500101008', '500101009', '500101010', '500101013', '500101014', '500101015', '500101018', '500101019', '500101020', '500101021', '500101022', '500101023', '500101024', '500101025', '500101026', '500101027', '500101028', '500101029', '500101030', '500101031', '500101032', '500101033', '500101034', '500101035', '500101036', '500101037', '500101038', '500101039', '500101040', '500101041', '500101042', '500101091', '500101092', '500101093', '500101094', '500101114', '500101115', '500101123', '500101166', '500101175', '500101176', '500101181', '500101184', '500101185', '500101188', '500101189', '500101190', '500101191', '500101193', '500101199', '500101209', '500101216', '500101219', '500105066', '500106002', '500106003', '500106004', '500119043', '500119044', '500119045', '500119046', '500119047', '500119048', '500119049', '500119050', '500119051', '500119052', '500119053', '500119054', '500119055', '500119056', '500119057', '500119058', '500119059', '500119060', '500119061', '500119062', '500119063', '500119064', '500119065', '500119066', '500119067', '500119068', '500119069', '500119070', '500119071', '500119072', '500119074', '500119075', '500119076', '500119077', '500119078', '500119079', '500119080', '500119081', '500119082', '500119083', '500119084', '500119085', '500119086', '500119087', '500119088', '500119089', '500119090', '500119091']\n"
          ]
        }
      ],
      "source": [
        "with open(\"./data_sno_test_set.txt\", \"r\") as f:\n",
        "    predict_stns = f.read().split()\n",
        "    predict_stns.sort()\n",
        "print(\"predict_stns:\", predict_stns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1_ZwZr6C_fZS"
      },
      "outputs": [],
      "source": [
        "def read_data(stn, mode):\n",
        "  data = []\n",
        "  x = []\n",
        "  y = []\n",
        "  path = f\"./data/{stn}_{mode}.txt\"\n",
        "\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      tmp_list = line.split()\n",
        "      for i in range(len(tmp_list)):\n",
        "        if i not in [0, 1, 2]:\n",
        "          tmp_list[i] = float(tmp_list[i])\n",
        "      # if tmp_list[1] in week_list:\n",
        "      min = int(tmp_list[2][:2]) * 60 + int(tmp_list[2][3:])\n",
        "      weekday = int(tmp_list[4])\n",
        "      all_min = 1440 * (weekday - 1) + min\n",
        "      if tmp_list[4] == 5 and min > 1440 - 60 * 6:\n",
        "        tmp_list[5] = 0\n",
        "\n",
        "      def sin_a(a, b):\n",
        "        return np.sin(a * 2 * np.pi / b)\n",
        "      def cos_a(a, b):\n",
        "        return np.cos(a * 2 * np.pi / b)\n",
        "      k = 1440\n",
        "      x_input = []\n",
        "      rain = float(tmp_list[7])\n",
        "      # for i in range(1, 7):\n",
        "      #   x_input.append(sin_a(min, k * i))\n",
        "      #   x_input.append(cos_a(min, k * i))\n",
        "      x_input = [min, all_min] + tmp_list[5:8]\n",
        "      y_label = int(tmp_list[8])\n",
        "    \n",
        "      \n",
        "      frac = y_label/ tmp_list[3]\n",
        "      if mode != \"train\":\n",
        "        x.append(list(x_input))\n",
        "        y.append(y_label)\n",
        "      elif mode == 'train':\n",
        "        N = 10\n",
        "        for i in range(int(N * 3 * ( abs(frac - 1/3) + abs(frac - 2/3))) - (N - 1)):\n",
        "          x.append(list(x_input))\n",
        "          y.append(y_label)\n",
        "          # if weekday in [6, 7]:\n",
        "          #   for i in range(2):\n",
        "          #     x.append(list(x_input))\n",
        "          #     y.append(y_label)\n",
        "      # x.append(list(x_input))\n",
        "      # y.append(y_label)\n",
        "          \n",
        "      data.append(tmp_list)\n",
        "      \n",
        "  # print(\"data:\", data)\n",
        "  # print(\"x_train:\", x)\n",
        "  # print(\"y_train:\", y)\n",
        "  data = np.array(data)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  scaler = StandardScaler()\n",
        "  # x = scaler.fit_transform(x)\n",
        "  # y = scaler.transform(y)\n",
        "  return data, x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BsdGB3ifOg2O"
      },
      "outputs": [],
      "source": [
        "def Err_func(b_predict, b_truth, total):\n",
        "    return 3 * abs(b_predict - b_truth) / total * ( abs((3 * b_truth - total)/(3 *total)) + abs((3 * b_truth - 2 * total)/(3 * total)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5tC5e_rPOkFh"
      },
      "outputs": [],
      "source": [
        "def val(predic_y, y, total):\n",
        "  err = 0\n",
        "  for i in range(len(y)):\n",
        "    predic_y[i] = predic_y[i] if predic_y[i] > 0 else 0 \n",
        "    err += Err_func(float(predic_y[i]), y[i], total)\n",
        "\n",
        "  return err / len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mJscZbxSqTVP"
      },
      "outputs": [],
      "source": [
        "def Load_stn_tot():\n",
        "  with open(\"./data_stn_tot.json\", 'r') as f:\n",
        "    stn_tot = json.load(f)\n",
        "  return dict(stn_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f99RZ62fAP6Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500101001: train: 0.17540933370873796, \u001b[34mval: 0.26690147149850235\u001b[0m, avg_train: 0.17540933370873796, avg_val: 0.26690147149850235\n",
            "500101002: train: 0.15493528349226973, \u001b[34mval: 0.221850140824016  \u001b[0m, avg_train: 0.16517230860050386, avg_val: 0.24437580616125917\n",
            "500101003: train: 0.27070924617118325, \u001b[34mval: 0.39721228970149586\u001b[0m, avg_train: 0.2003512877907303 , avg_val: 0.2953213006746714 \n",
            "500101004: train: 0.3093316561687693 , \u001b[34mval: 0.464295247047616  \u001b[0m, avg_train: 0.22759637988524006, avg_val: 0.33756478726790756\n",
            "500101005: train: 0.23989049705367177, \u001b[34mval: 0.3092969802156967 \u001b[0m, avg_train: 0.2300552033189264 , avg_val: 0.33191122585746535\n",
            "500101006: train: 0.214418112549331  , \u001b[34mval: 0.32478913169692475\u001b[0m, avg_train: 0.22744902152399382, avg_val: 0.3307242101640419 \n",
            "500101007: train: 0.21617532952783314, \u001b[34mval: 0.28568911754619   \u001b[0m, avg_train: 0.22583849409597084, avg_val: 0.3242906255043488 \n",
            "500101008: train: 0.41528577006080225, \u001b[34mval: 0.4511149098197921 \u001b[0m, avg_train: 0.24951940359157476, avg_val: 0.3401436610437792 \n",
            "500101009: train: 0.397580203721364  , \u001b[34mval: 0.35435461675498076\u001b[0m, avg_train: 0.2659706036059958 , avg_val: 0.34172265612280156\n",
            "500101010: train: 0.31547519375732197, \u001b[34mval: 0.472599381914974  \u001b[0m, avg_train: 0.27092106262112836, avg_val: 0.35481032870201884\n",
            "500101013: train: 0.35946026766549205, \u001b[34mval: 0.5348639817029677 \u001b[0m, avg_train: 0.27897008126152506, avg_val: 0.371178842611196  \n",
            "500101014: train: 0.4202990843420137 , \u001b[34mval: 0.42866470556983904\u001b[0m, avg_train: 0.29074749818489914, avg_val: 0.37596933119108294\n",
            "500101015: train: 0.2333394390375596 , \u001b[34mval: 0.4112781810038135 \u001b[0m, avg_train: 0.2863314936351038 , avg_val: 0.37868539656129296\n",
            "500101018: train: 0.503195967011698  , \u001b[34mval: 0.5606922651596453 \u001b[0m, avg_train: 0.30182181316200335, avg_val: 0.39168588717546093\n",
            "500101019: train: 0.2859294687524157 , \u001b[34mval: 0.33832342550091654\u001b[0m, avg_train: 0.3007623235346975 , avg_val: 0.3881283897304913 \n",
            "500101020: train: 0.0                , \u001b[34mval: 0.0                \u001b[0m, avg_train: 0.2819646783137789 , avg_val: 0.3638703653723356 \n",
            "500101021: train: 0.25852076233311705, \u001b[34mval: 0.3114249307486735 \u001b[0m, avg_train: 0.2805856244325635 , avg_val: 0.3607853398062378 \n",
            "500101022: train: 0.12618007384164354, \u001b[34mval: 0.18950479682023474\u001b[0m, avg_train: 0.27200753828862356, avg_val: 0.3512697540847932 \n",
            "500101023: train: 0.2035114875734998 , \u001b[34mval: 0.26252393852724615\u001b[0m, avg_train: 0.26840248298782754, avg_val: 0.34659892168702755\n",
            "500101024: train: 0.11125899152336505, \u001b[34mval: 0.16704598098353035\u001b[0m, avg_train: 0.26054530841460444, avg_val: 0.3376212746518527 \n",
            "500101025: train: 0.08316743361174611, \u001b[34mval: 0.15703006616583884\u001b[0m, avg_train: 0.25209874294780166, avg_val: 0.3290216932953759 \n",
            "500101026: train: 0.3379017883424156 , \u001b[34mval: 0.37073411007222207\u001b[0m, avg_train: 0.25599888137482957, avg_val: 0.33091771223977795\n",
            "500101027: train: 0.24279974561806456, \u001b[34mval: 0.27866580747055114\u001b[0m, avg_train: 0.2554250059071441 , avg_val: 0.32864589029328983\n",
            "500101028: train: 0.24428026268861858, \u001b[34mval: 0.3627038375741721 \u001b[0m, avg_train: 0.2549606416063722 , avg_val: 0.3300649714299933 \n",
            "500101029: train: 0.2228036024170647 , \u001b[34mval: 0.23315697919117412\u001b[0m, avg_train: 0.2536743600387999 , avg_val: 0.32618865174044054\n",
            "500101030: train: 0.15693150468237965, \u001b[34mval: 0.22954444820414463\u001b[0m, avg_train: 0.2499534809866299 , avg_val: 0.32247156698904456\n",
            "500101031: train: 0.25540145172516215, \u001b[34mval: 0.3463493823675829 \u001b[0m, avg_train: 0.2501552576806496 , avg_val: 0.323355930521583  \n",
            "500101032: train: 0.09778341182339068, \u001b[34mval: 0.12931133885230267\u001b[0m, avg_train: 0.24471340604289038, avg_val: 0.3164257665333944 \n",
            "500101033: train: 0.10974778441753624, \u001b[34mval: 0.22519256025928489\u001b[0m, avg_train: 0.24005941909029194, avg_val: 0.31327979390325267\n",
            "500101034: train: 0.12810594016567373, \u001b[34mval: 0.23456650089222197\u001b[0m, avg_train: 0.23632763645947136, avg_val: 0.3106560174695517 \n",
            "500101035: train: 0.13364415287332398, \u001b[34mval: 0.1943607902793074 \u001b[0m, avg_train: 0.23301526602120853, avg_val: 0.30690455852793086\n",
            "500101036: train: 0.1352526894318203 , \u001b[34mval: 0.1557858334621494 \u001b[0m, avg_train: 0.22996018550279015, avg_val: 0.3021820983696252 \n",
            "500101037: train: 0.2146183454364721 , \u001b[34mval: 0.2564051005431526 \u001b[0m, avg_train: 0.22949528125835628, avg_val: 0.30079491661730784\n",
            "500101038: train: 0.1352240948103557 , \u001b[34mval: 0.1692293135736771 \u001b[0m, avg_train: 0.22672259930400332, avg_val: 0.29692534005720106\n",
            "500101039: train: 0.21950493825983552, \u001b[34mval: 0.2313941358102164 \u001b[0m, avg_train: 0.2265163804170271 , avg_val: 0.29505301993585864\n",
            "500101040: train: 0.2785366500729765 , \u001b[34mval: 0.2834712158190797 \u001b[0m, avg_train: 0.22796138790747011, avg_val: 0.29473130315483703\n",
            "500101041: train: 0.20687341298453032, \u001b[34mval: 0.20401032423359558\u001b[0m, avg_train: 0.22739144263928254, avg_val: 0.2922793848056143 \n",
            "500101042: train: 0.1860280522440035 , \u001b[34mval: 0.2781297419055741 \u001b[0m, avg_train: 0.22630293236572258, avg_val: 0.29190702578192895\n",
            "500101091: train: 0.2261475314355643 , \u001b[34mval: 0.26514218318512234\u001b[0m, avg_train: 0.22629894772648776, avg_val: 0.29122074776662626\n",
            "500101092: train: 0.21273600129101836, \u001b[34mval: 0.3181687104736817 \u001b[0m, avg_train: 0.22595987406560103, avg_val: 0.29189444683430266\n",
            "500101093: train: 0.20169433524672647, \u001b[34mval: 0.2761010037012644 \u001b[0m, avg_train: 0.22536803165538458, avg_val: 0.29150924090422853\n",
            "500101094: train: 0.23331390619957326, \u001b[34mval: 0.26701503660683723\u001b[0m, avg_train: 0.22555721914453192, avg_val: 0.29092604556381446\n",
            "500101114: train: 0.3256140396164605 , \u001b[34mval: 0.3026020112971295 \u001b[0m, avg_train: 0.2278841219462047 , avg_val: 0.2911975796506357 \n",
            "500101115: train: 0.2226743898303854 , \u001b[34mval: 0.27817804328333606\u001b[0m, avg_train: 0.22776571894357245, avg_val: 0.29090168109683345\n",
            "500101123: train: 0.13690361318673544, \u001b[34mval: 0.2094325938715516 \u001b[0m, avg_train: 0.22574656103786495, avg_val: 0.28909125693627163\n",
            "500101166: train: 0.11282382068586148, \u001b[34mval: 0.24275289936243752\u001b[0m, avg_train: 0.22329171885629967, avg_val: 0.2880839013368405 \n",
            "500101175: train: 0.25734068130001775, \u001b[34mval: 0.31866936364852466\u001b[0m, avg_train: 0.22401616486574047, avg_val: 0.28873465585411034\n",
            "500101176: train: 0.20781588728176711, \u001b[34mval: 0.2461140724662636 \u001b[0m, avg_train: 0.223678659082741  , avg_val: 0.28784672703353026\n",
            "500101181: train: 0.20673756583748493, \u001b[34mval: 0.28245530850971745\u001b[0m, avg_train: 0.2233329224858991 , avg_val: 0.28773669808406466\n",
            "500101184: train: 0.2431140975230353 , \u001b[34mval: 0.32457993317919853\u001b[0m, avg_train: 0.2237285459866418 , avg_val: 0.28847356278596736\n",
            "500101185: train: 0.3536225150670168 , \u001b[34mval: 0.48176736355298166\u001b[0m, avg_train: 0.2262754865568452 , avg_val: 0.29226363731081073\n",
            "500101188: train: 0.14035907080177923, \u001b[34mval: 0.2777807771475667 \u001b[0m, avg_train: 0.2246232477923247 , avg_val: 0.2919851207692099 \n",
            "500101189: train: 0.44936695173815877, \u001b[34mval: 0.47233091110804143\u001b[0m, avg_train: 0.2288636950365857 , avg_val: 0.29538787153032   \n",
            "500101190: train: 0.2000720346318995 , \u001b[34mval: 0.26172466853147264\u001b[0m, avg_train: 0.22833051614020264, avg_val: 0.29476447888219315\n",
            "500101191: train: 0.1430717570673905 , \u001b[34mval: 0.23723987067224722\u001b[0m, avg_train: 0.22678035688433335, avg_val: 0.29371857691473957\n",
            "500101193: train: 0.13882995838050538, \u001b[34mval: 0.11880971866869579\u001b[0m, avg_train: 0.22520981405390783, avg_val: 0.29059520444606024\n",
            "500101199: train: 0.2839216746022404 , \u001b[34mval: 0.30752560102578586\u001b[0m, avg_train: 0.22623984669510663, avg_val: 0.290892228947459  \n",
            "500101209: train: 0.11976406770677188, \u001b[34mval: 0.16159570393918957\u001b[0m, avg_train: 0.22440405740220432, avg_val: 0.28866297851628187\n",
            "500101216: train: 0.29610740515538186, \u001b[34mval: 0.3041356102285955 \u001b[0m, avg_train: 0.22561936838107174, avg_val: 0.28892522651140584\n",
            "500101219: train: 0.32941793297768746, \u001b[34mval: 0.25904332269469577\u001b[0m, avg_train: 0.227349344457682  , avg_val: 0.2884271947811273 \n",
            "500105066: train: 0.2849569376337113 , \u001b[34mval: 0.45696739226041966\u001b[0m, avg_train: 0.22829373123105953, avg_val: 0.2911901488381649 \n",
            "500106002: train: 0.17137926488383745, \u001b[34mval: 0.2872806668309445 \u001b[0m, avg_train: 0.22737575596739468, avg_val: 0.2911270926767581 \n",
            "500106003: train: 0.1877588472088834 , \u001b[34mval: 0.22723710495731061\u001b[0m, avg_train: 0.226746916145831  , avg_val: 0.2901129658875605 \n",
            "500106004: train: 0.2704888192879784 , \u001b[34mval: 0.3554594071479639 \u001b[0m, avg_train: 0.22743038338242705, avg_val: 0.29113400403225437\n",
            "500119043: train: 0.10125415197621221, \u001b[34mval: 0.16537314562401348\u001b[0m, avg_train: 0.2254892105915622 , avg_val: 0.2891992215952045 \n",
            "500119044: train: 0.21011227329212678, \u001b[34mval: 0.2950233610432249 \u001b[0m, avg_train: 0.22525622669308593, avg_val: 0.2892874661322957 \n",
            "500119045: train: 0.172831677381981  , \u001b[34mval: 0.33456678941292317\u001b[0m, avg_train: 0.22447377073321867, avg_val: 0.28996327692752893\n",
            "500119046: train: 0.16184015163750182, \u001b[34mval: 0.23732688096111226\u001b[0m, avg_train: 0.22355268809945814, avg_val: 0.289189212280964  \n",
            "500119047: train: 0.17739445488931319, \u001b[34mval: 0.2588632201565672 \u001b[0m, avg_train: 0.22288372819786184, avg_val: 0.28874970514872633\n",
            "500119048: train: 0.16664476166181566, \u001b[34mval: 0.2102707352750071 \u001b[0m, avg_train: 0.22208031439020404, avg_val: 0.2876285770076732 \n",
            "500119049: train: 0.11018749332685658, \u001b[34mval: 0.15114391527501575\u001b[0m, avg_train: 0.2205043591639597 , avg_val: 0.28570625782833997\n",
            "500119050: train: 0.17287838413937115, \u001b[34mval: 0.27319104345689216\u001b[0m, avg_train: 0.2198428872886182 , avg_val: 0.28553243540651435\n",
            "500119051: train: 0.10722615028734234, \u001b[34mval: 0.19478338272145015\u001b[0m, avg_train: 0.21830019226120345, avg_val: 0.28428929769849975\n",
            "500119052: train: 0.20418271326057288, \u001b[34mval: 0.28468189675325234\u001b[0m, avg_train: 0.21810941551795168, avg_val: 0.2842946030911316 \n",
            "500119053: train: 0.2028228817977278 , \u001b[34mval: 0.28850501279823904\u001b[0m, avg_train: 0.21790559506834872, avg_val: 0.2843507418872263 \n",
            "500119054: train: 0.15379309800467234, \u001b[34mval: 0.2111351630256558 \u001b[0m, avg_train: 0.2170620095806688 , avg_val: 0.2833873790074688 \n",
            "500119055: train: 0.28230157932146005, \u001b[34mval: 0.32318465804562546\u001b[0m, avg_train: 0.21790927672015956, avg_val: 0.28390422678718513\n",
            "500119056: train: 0.2304450281782253 , \u001b[34mval: 0.2825277299890628 \u001b[0m, avg_train: 0.21806999148244244, avg_val: 0.2838865793923374 \n",
            "500119057: train: 0.21197083539853767, \u001b[34mval: 0.2413053629644297 \u001b[0m, avg_train: 0.21799278697505126, avg_val: 0.2833475766527436 \n",
            "500119058: train: 0.19663923915774129, \u001b[34mval: 0.3542927249280184 \u001b[0m, avg_train: 0.21772586762733487, avg_val: 0.2842343910061846 \n",
            "500119059: train: 0.09282865515261086, \u001b[34mval: 0.07854164634551566\u001b[0m, avg_train: 0.21618392673258519, avg_val: 0.2816949744054356 \n",
            "500119060: train: 0.2202355186582455 , \u001b[34mval: 0.2797769348543724 \u001b[0m, avg_train: 0.2162333363902152 , avg_val: 0.28167158367920314\n",
            "500119061: train: 0.1976655260612934 , \u001b[34mval: 0.26316785687605126\u001b[0m, avg_train: 0.21600962783203542, avg_val: 0.28144864721169527\n",
            "500119062: train: 0.14808744669224475, \u001b[34mval: 0.1789312194426975 \u001b[0m, avg_train: 0.2152010304375141 , avg_val: 0.28022820164301676\n",
            "500119063: train: 0.13994916691673218, \u001b[34mval: 0.14052027000150402\u001b[0m, avg_train: 0.21431571439609312, avg_val: 0.27858457891782246\n",
            "500119064: train: 0.13084196226889006, \u001b[34mval: 0.1638590597777787 \u001b[0m, avg_train: 0.2133450893713582 , avg_val: 0.27725056125340336\n",
            "500119065: train: 0.1809284870040303 , \u001b[34mval: 0.2484435797055197 \u001b[0m, avg_train: 0.2129724847464464 , avg_val: 0.2769194465229679 \n",
            "500119066: train: 0.16636352693213008, \u001b[34mval: 0.2513701355738739 \u001b[0m, avg_train: 0.21244283749855644, avg_val: 0.27662911344400093\n",
            "500119067: train: 0.11502982447004591, \u001b[34mval: 0.18332275195575276\u001b[0m, avg_train: 0.21134830926228104, avg_val: 0.27558072735986333\n",
            "500119068: train: 0.12311935611167951, \u001b[34mval: 0.15729769425313456\u001b[0m, avg_train: 0.2103679875606077 , avg_val: 0.2742664714364552 \n",
            "500119069: train: 0.1836155870595588 , \u001b[34mval: 0.20240972428740306\u001b[0m, avg_train: 0.21007400513751925, avg_val: 0.2734768368523997 \n",
            "500119070: train: 0.3288854417368495 , \u001b[34mval: 0.26665198359393416\u001b[0m, avg_train: 0.21136543379620765, avg_val: 0.2734026536648077 \n",
            "500119071: train: 0.14207070474940167, \u001b[34mval: 0.2547000351674816 \u001b[0m, avg_train: 0.21062032918280113, avg_val: 0.27320155024010523\n",
            "500119072: train: 0.18209828965680838, \u001b[34mval: 0.22563652795109354\u001b[0m, avg_train: 0.21031690323039692, avg_val: 0.2726955393646902 \n",
            "500119074: train: 0.17979402697100805, \u001b[34mval: 0.22280664153869556\u001b[0m, avg_train: 0.20999560979608758, avg_val: 0.27217039307178503\n",
            "500119075: train: 0.14196597411681747, \u001b[34mval: 0.22682388180188248\u001b[0m, avg_train: 0.20928696775776187, avg_val: 0.2716980335793902 \n",
            "500119076: train: 0.11828737147957154, \u001b[34mval: 0.17437742206189932\u001b[0m, avg_train: 0.20834882758994547, avg_val: 0.270694728306014  \n",
            "500119077: train: 0.21322152795424978, \u001b[34mval: 0.2872280767861185 \u001b[0m, avg_train: 0.2083985490222343 , avg_val: 0.27086343594356604\n",
            "500119078: train: 0.37731725756566653, \u001b[34mval: 0.33043198144432895\u001b[0m, avg_train: 0.21010479860348108, avg_val: 0.2714651384233717 \n",
            "500119079: train: 0.3728899448701791 , \u001b[34mval: 0.3726587242931752 \u001b[0m, avg_train: 0.21173265006614805, avg_val: 0.27247707428206974\n",
            "500119080: train: 0.2013672697983156 , \u001b[34mval: 0.196114060902092  \u001b[0m, avg_train: 0.21163002253874377, avg_val: 0.27172100484266404\n",
            "500119081: train: 0.20380893511581108, \u001b[34mval: 0.3224901266397669 \u001b[0m, avg_train: 0.21155334521106797, avg_val: 0.27221874133087093\n",
            "500119082: train: 0.34288101553660427, \u001b[34mval: 0.2879175678303334 \u001b[0m, avg_train: 0.21282837113655861, avg_val: 0.2723711571221279 \n",
            "500119083: train: 0.21850892329380447, \u001b[34mval: 0.23626615639313264\u001b[0m, avg_train: 0.2128829918303783 , avg_val: 0.2720239936535798 \n",
            "500119084: train: 0.17728713922320433, \u001b[34mval: 0.2593356082672036 \u001b[0m, avg_train: 0.21254398371030994, avg_val: 0.2719031518879953 \n",
            "500119085: train: 0.17304863727390704, \u001b[34mval: 0.26249008457387496\u001b[0m, avg_train: 0.21217138610241937, avg_val: 0.271814349366164  \n",
            "500119086: train: 0.1760982563836308 , \u001b[34mval: 0.19574273274821954\u001b[0m, avg_train: 0.21183425404897277, avg_val: 0.2711033996781458 \n",
            "500119087: train: 0.18298312961793825, \u001b[34mval: 0.23129325679975749\u001b[0m, avg_train: 0.21156711400794467, avg_val: 0.27073478724408667\n",
            "500119088: train: 0.19991910378451652, \u001b[34mval: 0.27653729536222055\u001b[0m, avg_train: 0.21146025152883063, avg_val: 0.2707880212635191 \n",
            "500119089: train: 0.13792803402601395, \u001b[34mval: 0.20307327499121505\u001b[0m, avg_train: 0.2107917768242596 , avg_val: 0.2701724326610436 \n",
            "500119090: train: 0.1987101105488724 , \u001b[34mval: 0.2735406970537305 \u001b[0m, avg_train: 0.21068293298394078, avg_val: 0.270202777385302  \n",
            "500119091: train: 0.22830158062318426, \u001b[34mval: 0.21687030454176232\u001b[0m, avg_train: 0.2108402423378626 , avg_val: 0.2697265945920561 \n",
            "final: train: 0.2108402423378626, val: 0.2697265945920561\n"
          ]
        }
      ],
      "source": [
        "all_val_err = 0\n",
        "all_train_err = 0\n",
        "count = 0\n",
        "predict_file = open(\"./XGboost_predict.csv\", 'w')\n",
        "predict_file.write(\"id,sbi\\n\")\n",
        "stn_tot = Load_stn_tot()\n",
        "val_xgb = {}\n",
        "# predict_stns = ['500101001']\n",
        "for stn in predict_stns:\n",
        "  count += 1\n",
        "  data_train, x_train, y_train = read_data(stn, 'train')\n",
        "  data_val, x_val, y_val = read_data(stn, 'val')\n",
        "  data_test, x_test, y_test = read_data(stn, 'test')\n",
        "\n",
        "\n",
        "  model = XGBRegressor(n_estimators=100, learning_rate= 0.3)\n",
        "  model.fit(x_train, y_train)\n",
        "  pre_train = model.predict(x_train)\n",
        "\n",
        "  pre_val = model.predict(x_val)\n",
        "  train_err = val(pre_train, y_train, int(stn_tot[stn]))\n",
        "  val_err = val(pre_val, y_val, int(stn_tot[stn]))\n",
        "  all_train_err += train_err\n",
        "  all_val_err += val_err\n",
        "  print(f\"{stn}: train: {train_err:<19}, \\033[34mval: {val_err:<19}\\033[0m, avg_train: {all_train_err / count:<19}, avg_val: {all_val_err/count:<19}\")\n",
        "  \n",
        "  # plt.figure(figsize=(80, 5), dpi=300)\n",
        "  # plt.plot(pre_train, label='pre_train', color='b')\n",
        "  # plt.plot(y_train, label='truth', color='darkorange')\n",
        "  # plt.legend()\n",
        "  # plt.show()\n",
        "  \n",
        "  # plt.figure(figsize=(80, 5), dpi=300)\n",
        "  # plt.plot(pre_val, label='pre_train', color='b')\n",
        "  # plt.plot(y_val, label='truth', color='darkorange')\n",
        "  # plt.legend()\n",
        "  # plt.show()\n",
        "  \n",
        "  pre_test = model.predict(x_test)\n",
        "  for i in range(len(data_test)):\n",
        "    if data_test[i][2][3:] in [\"00\", \"20\", \"40\"]:\n",
        "      pre_test[i] = pre_test[i] if pre_test[i] > 0 else 0\n",
        "      id = f'{data_test[i][1]}_{int(data_test[i][0])}_{data_test[i][2]}'\n",
        "      predict_file.write(f\"{id},{pre_test[i]}\\n\")\n",
        "      \n",
        "  val_xgb[stn] = {}\n",
        "  val_xgb[stn]['val'] = val_err\n",
        "  val_xgb[stn]['tarin'] = train_err\n",
        "\n",
        "predict_file.close()\n",
        "print(f\"final: train: {all_train_err / len(predict_stns)}, val: {all_val_err / len(predict_stns)}\")\n",
        "with open(\"./val_XGBoost.json\", 'w') as f:\n",
        "  json.dump(val_xgb, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
