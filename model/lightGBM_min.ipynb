{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "HEmT9VhRK_dF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from time import localtime, strftime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wfCq6h0SA49",
        "outputId": "c389dc8c-65c0-4b58-db81-ba38adb63848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predict_stns: ['500101001', '500101002', '500101003', '500101004', '500101005', '500101006', '500101007', '500101008', '500101009', '500101010', '500101013', '500101014', '500101015', '500101018', '500101019', '500101020', '500101021', '500101022', '500101023', '500101024', '500101025', '500101026', '500101027', '500101028', '500101029', '500101030', '500101031', '500101032', '500101033', '500101034', '500101035', '500101036', '500101037', '500101038', '500101039', '500101040', '500101041', '500101042', '500101091', '500101092', '500101093', '500101094', '500101114', '500101115', '500101123', '500101166', '500101175', '500101176', '500101181', '500101184', '500101185', '500101188', '500101189', '500101190', '500101191', '500101193', '500101199', '500101209', '500101216', '500101219', '500105066', '500106002', '500106003', '500106004', '500119043', '500119044', '500119045', '500119046', '500119047', '500119048', '500119049', '500119050', '500119051', '500119052', '500119053', '500119054', '500119055', '500119056', '500119057', '500119058', '500119059', '500119060', '500119061', '500119062', '500119063', '500119064', '500119065', '500119066', '500119067', '500119068', '500119069', '500119070', '500119071', '500119072', '500119074', '500119075', '500119076', '500119077', '500119078', '500119079', '500119080', '500119081', '500119082', '500119083', '500119084', '500119085', '500119086', '500119087', '500119088', '500119089', '500119090', '500119091']\n"
          ]
        }
      ],
      "source": [
        "with open(\"./data_sno_test_set.txt\", \"r\") as f:\n",
        "    predict_stns = f.read().split()\n",
        "    predict_stns.sort()\n",
        "print(\"predict_stns:\", predict_stns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "BsdGB3ifOg2O"
      },
      "outputs": [],
      "source": [
        "def Err_func(b_predict, b_truth, total):\n",
        "    return 3 * abs(b_predict - b_truth) / total * ( abs((3 * b_truth - total)/(3 *total)) + abs((3 * b_truth - 2 * total)/(3 * total)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "5tC5e_rPOkFh"
      },
      "outputs": [],
      "source": [
        "def val(predic_y, y, total):\n",
        "  err = 0\n",
        "  for i in range(len(y)):\n",
        "    err += Err_func(float(predic_y[i]), y[i], total)\n",
        "\n",
        "  return err / len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "mJscZbxSqTVP"
      },
      "outputs": [],
      "source": [
        "def Load_stn_tot():\n",
        "  with open(\"./data_stn_tot.json\", 'r') as f:\n",
        "    stn_tot = json.load(f)\n",
        "  return dict(stn_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for released days\n",
        "def Load_datelist(mode):\n",
        "    '''\n",
        "    mode`: should be a `str` in `['train', 'val', 'test', 'release']`\\\\\n",
        "    '''\n",
        "    mode_list = ['train', 'val', 'test', 'release']\n",
        "    if mode in mode_list:\n",
        "        with open(f\"data_datelist_{mode}.txt\", 'r') as f:\n",
        "            datelist = f.read().split() \n",
        "        datelist.sort()\n",
        "        return datelist\n",
        "    else:\n",
        "        raise Exception(f'wrong mode, mode should be a `str` in {mode_list}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "1_ZwZr6C_fZS"
      },
      "outputs": [],
      "source": [
        "def read_data(stn, mode):\n",
        "  data = []\n",
        "  x = []\n",
        "  y = []\n",
        "  path = f\"./data/{stn}_{mode}.txt\"\n",
        "\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      tmp_list = line.split()\n",
        "      for i in range(len(tmp_list)):\n",
        "        if i not in [0, 1, 2]:\n",
        "          tmp_list[i] = float(tmp_list[i])\n",
        "      # if tmp_list[1] in week_list:\n",
        "      min = int(tmp_list[2][:2]) * 60 + int(tmp_list[2][3:])\n",
        "      weekday = int(tmp_list[4])\n",
        "      all_min = 1440 * (weekday - 1) + min\n",
        "      if tmp_list[4] == 5 and min > 1440 - 60 * 6:\n",
        "        tmp_list[5] = 0\n",
        "\n",
        "      def sin_a(a, b):\n",
        "        return np.sin(a * 2 * np.pi / b)\n",
        "      def cos_a(a, b):\n",
        "        return np.cos(a * 2 * np.pi / b)\n",
        "      k = 1440\n",
        "      x_input = []\n",
        "      rain = float(tmp_list[7])\n",
        "      # for i in range(1, 7):\n",
        "      #   x_input.append(sin_a(min, k * i))\n",
        "      #   x_input.append(cos_a(min, k * i))\n",
        "      x_input = [min, all_min] + tmp_list[5:8]\n",
        "      y_label = int(tmp_list[8])\n",
        "    \n",
        "      \n",
        "      frac = y_label/ tmp_list[3]\n",
        "      if mode != \"train\":\n",
        "        x.append(list(x_input))\n",
        "        y.append(y_label)\n",
        "      elif mode == 'train':\n",
        "        N = 10\n",
        "        for i in range(int(N * 3 * ( abs(frac - 1/3) + abs(frac - 2/3))) - (N - 1)):\n",
        "          x.append(list(x_input))\n",
        "          y.append(y_label)\n",
        "          # if weekday in [6, 7]:\n",
        "          #   for i in range(2):\n",
        "          #     x.append(list(x_input))\n",
        "          #     y.append(y_label)\n",
        "      # x.append(list(x_input))\n",
        "      # y.append(y_label)\n",
        "          \n",
        "      data.append(tmp_list)\n",
        "      \n",
        "  # print(\"data:\", data)\n",
        "  # print(\"x_train:\", x)\n",
        "  # print(\"y_train:\", y)\n",
        "  data = np.array(data)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  scaler = StandardScaler()\n",
        "  # x = scaler.fit_transform(x)\n",
        "  # y = scaler.transform(y)\n",
        "  return data, x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "f99RZ62fAP6Q"
      },
      "outputs": [],
      "source": [
        "def run(num_leaves, learning_rate, feature_fraction, num_round):\n",
        "  all_val_err = 0\n",
        "  all_train_err = 0\n",
        "  count = 0\n",
        "  stn_tot = Load_stn_tot()\n",
        "  val_json = {}\n",
        "\n",
        "  predict_file = open(f\"./lightGBM_predict_{strftime('%m%d-%H-%M-%S', localtime())}.csv\", 'w')\n",
        "  predict_file.write(\"id,sbi\\n\")\n",
        "\n",
        "  predict_log_file = open(f\"./lightGBM_predict_log_{strftime('%m%d-%H-%M-%S', localtime())}.txt\", \"w\")\n",
        "  print(f\"date_val: {Load_datelist('val')}\")\n",
        "  print(f\"date_val: {Load_datelist('val')}\", file=predict_log_file)\n",
        "  print(f\"date_train: {Load_datelist('train')}\")\n",
        "  print(f\"date_train: {Load_datelist('train')}\", file=predict_log_file)\n",
        "  print(f\"date_train: {Load_datelist('test')}\")\n",
        "  print(f\"date_train: {Load_datelist('test')}\", file=predict_log_file)\n",
        "\n",
        "  # predict_stns = ['500101001']\n",
        "  for stn in predict_stns:\n",
        "    count += 1\n",
        "    data_train, x_train, y_train = read_data(stn, 'train')\n",
        "    data_val, x_val, y_val = read_data(stn, 'val')\n",
        "    data_test, x_test, y_test = read_data(stn, 'test')\n",
        "\n",
        "    train_data = lgb.Dataset(x_train, label=y_train)\n",
        "    val_data = lgb.Dataset(x_val, label=y_val, reference=train_data)\n",
        "    params = {\n",
        "      'objective': 'regression',\n",
        "      'metric': 'mse',\n",
        "      'boosting_type': 'gbdt',\n",
        "      'num_leaves': num_leaves,\n",
        "      'learning_rate': learning_rate,\n",
        "      'feature_fraction': feature_fraction,\n",
        "      'verbose' : -1,\n",
        "    }\n",
        "\n",
        "    # Train the model\n",
        "    \n",
        "    model = lgb.train(params, train_data, num_round, valid_sets=[val_data])\n",
        "    pre_train = model.predict(x_train)\n",
        "\n",
        "    pre_val = model.predict(x_val)\n",
        "    train_err = val(pre_train, y_train, int(stn_tot[stn]))\n",
        "    val_err = val(pre_val, y_val, int(stn_tot[stn]))\n",
        "    all_train_err += train_err\n",
        "    all_val_err += val_err\n",
        "    \n",
        "    log_info = f\"{stn}: train: {train_err:<19}, \\033[34mval: {val_err:<19}\\033[0m, avg_train: {all_train_err / count:<19}, avg_val: {all_val_err/count:<19}\"\n",
        "    print(log_info, file=predict_log_file)\n",
        "    print(log_info)\n",
        "    \n",
        "    val_json[stn] = {}\n",
        "    val_json[stn]['val'] = val_err\n",
        "    val_json[stn]['train'] = train_err\n",
        "    \n",
        "    \n",
        "    # plt.figure(figsize=(80, 5), dpi=300)\n",
        "    # plt.plot(pre_train, label='pre_train', color='b')\n",
        "    # plt.plot(y_train, label='truth', color='darkorange')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    \n",
        "    # plt.figure(figsize=(80, 5), dpi=300)\n",
        "    # plt.plot(pre_val, label='pre_train', color='b')\n",
        "    # plt.plot(y_val, label='truth', color='darkorange')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    # if all_val_err/count > 0.38:\n",
        "    #   return all_val_err/count\n",
        "    pre_test = model.predict(x_test)\n",
        "    for i in range(len(data_test)):\n",
        "      if data_test[i][2][3:] in [\"00\", \"20\", \"40\"]:\n",
        "        pre_test[i] = pre_test[i] if pre_test[i] > 0 else 0\n",
        "        id = f'{data_test[i][1]}_{int(data_test[i][0])}_{data_test[i][2]}'\n",
        "        predict_file.write(f\"{id},{pre_test[i]}\\n\")\n",
        "        \n",
        "  log_info = f\"final: train: {all_train_err / len(predict_stns)}, val: {all_val_err / len(predict_stns)}\"\n",
        "  print(log_info, file=predict_log_file)\n",
        "  print(log_info)\n",
        "\n",
        "  predict_file.close()\n",
        "  predict_log_file.close()\n",
        "  with open(\"./val_lightGBM.json\", 'w') as f: \n",
        "    json.dump(val_json, f, indent=2)\n",
        "  return all_val_err / len(predict_stns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a = []\n",
        "# b = []\n",
        "\n",
        "# for num_leaves in [16, 31, 64]:\n",
        "#     for feature_fraction in [0.5, 0.7, 0.9]:\n",
        "#         for learning_rate in [0.03, 0.05, 0.07, 0.09]:\n",
        "#             for num_round in [10, 25, 50, 75]:\n",
        "#                 print(num_leaves, feature_fraction, learning_rate, num_round)\n",
        "#                 a.append(run(num_leaves, learning_rate, feature_fraction, num_round))\n",
        "#                 b.append((num_leaves, feature_fraction, learning_rate, num_round))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_val: ['20231123', '20231124', '20231125', '20231126', '20231127', '20231128', '20231129']\n",
            "date_train: ['20231002', '20231003', '20231004', '20231005', '20231006', '20231007', '20231008', '20231009', '20231010', '20231011', '20231016', '20231017', '20231018', '20231019', '20231020', '20231025', '20231026', '20231027', '20231028', '20231029', '20231030', '20231031', '20231101', '20231102', '20231103', '20231104', '20231105', '20231106', '20231107', '20231108', '20231109', '20231110', '20231111', '20231112', '20231113', '20231114', '20231115', '20231116', '20231117', '20231118', '20231119', '20231120', '20231121', '20231122', '20231201', '20231202', '20231203', '20231204', '20231205', '20231206', '20231207', '20231208', '20231209', '20231210', '20231211', '20231212', '20231213']\n",
            "date_train: ['20231021', '20231022', '20231023', '20231024', '20231218', '20231219', '20231220', '20231221', '20231222', '20231223', '20231224']\n",
            "500101001: train: 0.19398627957417539, \u001b[34mval: 0.26467376524160935\u001b[0m, avg_train: 0.19398627957417539, avg_val: 0.26467376524160935\n",
            "500101002: train: 0.16991198762794033, \u001b[34mval: 0.21722046804911874\u001b[0m, avg_train: 0.18194913360105786, avg_val: 0.24094711664536406\n",
            "500101003: train: 0.296583703760254  , \u001b[34mval: 0.39593577185736817\u001b[0m, avg_train: 0.22016065698745657, avg_val: 0.2926100017160321 \n",
            "500101004: train: 0.34065254539055356, \u001b[34mval: 0.4538718703165522 \u001b[0m, avg_train: 0.2502836290882308 , avg_val: 0.33292546886616214\n",
            "500101005: train: 0.25703737721220427, \u001b[34mval: 0.3012715442193474 \u001b[0m, avg_train: 0.2516343787130255 , avg_val: 0.3265946839367992 \n",
            "500101006: train: 0.2349224264382297 , \u001b[34mval: 0.32053555207645623\u001b[0m, avg_train: 0.24884905333389287, avg_val: 0.32558482862674204\n",
            "500101007: train: 0.23489301513906133, \u001b[34mval: 0.28037316423240843\u001b[0m, avg_train: 0.24685533359177408, avg_val: 0.31912601942755153\n",
            "500101008: train: 0.44134815090288737, \u001b[34mval: 0.44736962483608134\u001b[0m, avg_train: 0.27116693575566325, avg_val: 0.33515647010361777\n",
            "500101009: train: 0.4251482015830331 , \u001b[34mval: 0.3537740215168757 \u001b[0m, avg_train: 0.2882759652920377 , avg_val: 0.3372250869273131 \n",
            "500101010: train: 0.3557608539879959 , \u001b[34mval: 0.47961476449454565\u001b[0m, avg_train: 0.2950244541616335 , avg_val: 0.35146405468403635\n",
            "500101013: train: 0.4045417115884179 , \u001b[34mval: 0.5200078451879455 \u001b[0m, avg_train: 0.30498056847315935, avg_val: 0.36678621745711903\n",
            "500101014: train: 0.4653341735048826 , \u001b[34mval: 0.4469605794256831 \u001b[0m, avg_train: 0.31834336889246967, avg_val: 0.3734674142878327 \n",
            "500101015: train: 0.2556125416836866 , \u001b[34mval: 0.42745052729729915\u001b[0m, avg_train: 0.31351792064564016, avg_val: 0.37761996144240706\n",
            "500101018: train: 0.5704758042171096 , \u001b[34mval: 0.5397559529884292 \u001b[0m, avg_train: 0.33187205518645946, avg_val: 0.38920110369569433\n",
            "500101019: train: 0.31486809698873675, \u001b[34mval: 0.32397014195776136\u001b[0m, avg_train: 0.33073845797327794, avg_val: 0.3848523729131655 \n",
            "500101020: train: 0.0                , \u001b[34mval: 0.0                \u001b[0m, avg_train: 0.31006730434994806, avg_val: 0.36079909960609263\n",
            "500101021: train: 0.2826027745808925 , \u001b[34mval: 0.3134214076461906 \u001b[0m, avg_train: 0.3084517437752977 , avg_val: 0.3580121765496278 \n",
            "500101022: train: 0.14103697175857965, \u001b[34mval: 0.18202628690093753\u001b[0m, avg_train: 0.2991509231077023 , avg_val: 0.3482351826802561 \n",
            "500101023: train: 0.2143484420074104 , \u001b[34mval: 0.26020778999498384\u001b[0m, avg_train: 0.2946876346287396 , avg_val: 0.3436021620126102 \n",
            "500101024: train: 0.12243997776035333, \u001b[34mval: 0.16121034707710297\u001b[0m, avg_train: 0.2860752517853203 , avg_val: 0.3344825712658348 \n",
            "500101025: train: 0.09253126910797713, \u001b[34mval: 0.16634291308084753\u001b[0m, avg_train: 0.27685887165782774, avg_val: 0.3264759208760735 \n",
            "500101026: train: 0.3635141467402345 , \u001b[34mval: 0.398144332664888  \u001b[0m, avg_train: 0.28079774779793715, avg_val: 0.32973357595738323\n",
            "500101027: train: 0.2758852631015249 , \u001b[34mval: 0.2740736267013918 \u001b[0m, avg_train: 0.2805841615067888 , avg_val: 0.3273135781636445 \n",
            "500101028: train: 0.2651409308690111 , \u001b[34mval: 0.37800324929825074\u001b[0m, avg_train: 0.27994069356354806, avg_val: 0.3294256477942531 \n",
            "500101029: train: 0.23945206007675607, \u001b[34mval: 0.23054158320631649\u001b[0m, avg_train: 0.2783211482240764 , avg_val: 0.3254702852107356 \n",
            "500101030: train: 0.1657953907386419 , \u001b[34mval: 0.22822439773921335\u001b[0m, avg_train: 0.2739932344746366 , avg_val: 0.3217300587695232 \n",
            "500101031: train: 0.28958043318687826, \u001b[34mval: 0.3367598886532503 \u001b[0m, avg_train: 0.2745705381306455 , avg_val: 0.32228671913558715\n",
            "500101032: train: 0.11015202282713991, \u001b[34mval: 0.12764708342659892\u001b[0m, avg_train: 0.26869844829837747, avg_val: 0.31533530357455186\n",
            "500101033: train: 0.12217450140380412, \u001b[34mval: 0.2310124075443348 \u001b[0m, avg_train: 0.2636458984054611 , avg_val: 0.31242761750454434\n",
            "500101034: train: 0.14478493050024321, \u001b[34mval: 0.23523005313738746\u001b[0m, avg_train: 0.2596838661419539 , avg_val: 0.30985436535897243\n",
            "500101035: train: 0.14656274811861428, \u001b[34mval: 0.18378903031734548\u001b[0m, avg_train: 0.2560347978186203 , avg_val: 0.30578774164795225\n",
            "500101036: train: 0.14920337369852507, \u001b[34mval: 0.1535284735923891 \u001b[0m, avg_train: 0.25269631581486734, avg_val: 0.3010296395212159 \n",
            "500101037: train: 0.23209991692559628, \u001b[34mval: 0.25835132903953406\u001b[0m, avg_train: 0.2520721825151925 , avg_val: 0.2997363573854074 \n",
            "500101038: train: 0.14844672248269683, \u001b[34mval: 0.1756654383870039 \u001b[0m, avg_train: 0.2490243748671779 , avg_val: 0.29608721270898375\n",
            "500101039: train: 0.23981916908907605, \u001b[34mval: 0.23371203343174618\u001b[0m, avg_train: 0.24876136898780357, avg_val: 0.29430506472963414\n",
            "500101040: train: 0.286613773589156  , \u001b[34mval: 0.2813736105146146 \u001b[0m, avg_train: 0.2498128246711745 , avg_val: 0.2939458576681058 \n",
            "500101041: train: 0.21499685462550097, \u001b[34mval: 0.20304673305903764\u001b[0m, avg_train: 0.24887185250777788, avg_val: 0.2914891245705634 \n",
            "500101042: train: 0.20689859191995438, \u001b[34mval: 0.28951131780853573\u001b[0m, avg_train: 0.24776729301862463, avg_val: 0.2914370770241943 \n",
            "500101091: train: 0.24279898007893697, \u001b[34mval: 0.2642241738278147 \u001b[0m, avg_train: 0.24763990037914546, avg_val: 0.2907393102755692 \n",
            "500101092: train: 0.23364498699822028, \u001b[34mval: 0.3252512048459667 \u001b[0m, avg_train: 0.24729002754462232, avg_val: 0.29160210763982913\n",
            "500101093: train: 0.2151304667396898 , \u001b[34mval: 0.287106987090047  \u001b[0m, avg_train: 0.24650564801279468, avg_val: 0.29149247055324906\n",
            "500101094: train: 0.2661634464680804 , \u001b[34mval: 0.25825178067555304\u001b[0m, avg_train: 0.24697369083315865, avg_val: 0.29070102555616106\n",
            "500101114: train: 0.3477430798084846 , \u001b[34mval: 0.3012541255408793 \u001b[0m, avg_train: 0.2493171649953755 , avg_val: 0.29094644648603823\n",
            "500101115: train: 0.23933786528126186, \u001b[34mval: 0.2680403649396545 \u001b[0m, avg_train: 0.24909036272914567, avg_val: 0.2904258537236204 \n",
            "500101123: train: 0.15081134775601923, \u001b[34mval: 0.2165664245512283 \u001b[0m, avg_train: 0.24690638461863174, avg_val: 0.288784533075345  \n",
            "500101166: train: 0.12452719988683472, \u001b[34mval: 0.23623562364322048\u001b[0m, avg_train: 0.24424596755924485, avg_val: 0.2876421654789945 \n",
            "500101175: train: 0.29485879660287334, \u001b[34mval: 0.29309644354005426\u001b[0m, avg_train: 0.2453228362623008 , avg_val: 0.2877582139483788 \n",
            "500101176: train: 0.22385169375708264, \u001b[34mval: 0.25928111056967157\u001b[0m, avg_train: 0.24487552079344208, avg_val: 0.2871649409613224 \n",
            "500101181: train: 0.2351388374697264 , \u001b[34mval: 0.27432503077463083\u001b[0m, avg_train: 0.24467681297050908, avg_val: 0.2869029019779205 \n",
            "500101184: train: 0.2710956149315814 , \u001b[34mval: 0.3207959139972175 \u001b[0m, avg_train: 0.24520518900973054, avg_val: 0.2875807622183065 \n",
            "500101185: train: 0.3874152483050817 , \u001b[34mval: 0.4821838807614738 \u001b[0m, avg_train: 0.2479936215449335 , avg_val: 0.2913965096407215 \n",
            "500101188: train: 0.1551062306686494 , \u001b[34mval: 0.27861585261607646\u001b[0m, avg_train: 0.24620732556654343, avg_val: 0.29115072777486295\n",
            "500101189: train: 0.4944792824747219 , \u001b[34mval: 0.4774422628911126 \u001b[0m, avg_train: 0.25089170211198075, avg_val: 0.2946656623996978 \n",
            "500101190: train: 0.22348780252436434, \u001b[34mval: 0.25777330203910054\u001b[0m, avg_train: 0.2503842224899878 , avg_val: 0.2939824705411682 \n",
            "500101191: train: 0.1614824521691842 , \u001b[34mval: 0.23743144481557926\u001b[0m, avg_train: 0.24876782666597322, avg_val: 0.2929542700734303 \n",
            "500101193: train: 0.14631401341332248, \u001b[34mval: 0.12789656102298866\u001b[0m, avg_train: 0.24693829428646158, avg_val: 0.2900068109832438 \n",
            "500101199: train: 0.31752058243261094, \u001b[34mval: 0.30047265720718214\u001b[0m, avg_train: 0.24817658004341156, avg_val: 0.29019042232050596\n",
            "500101209: train: 0.13214143537270917, \u001b[34mval: 0.14946130625783863\u001b[0m, avg_train: 0.24617597410081327, avg_val: 0.2877640582504599 \n",
            "500101216: train: 0.3225921780899903 , \u001b[34mval: 0.29546353474902715\u001b[0m, avg_train: 0.2474711639989349 , avg_val: 0.2878945578521306 \n",
            "500101219: train: 0.346527830237152  , \u001b[34mval: 0.26341300176279536\u001b[0m, avg_train: 0.24912210843623853, avg_val: 0.2874865319173084 \n",
            "500105066: train: 0.3122291090701702 , \u001b[34mval: 0.4536656969217624 \u001b[0m, avg_train: 0.2501566494302374 , avg_val: 0.2902107805239388 \n",
            "500106002: train: 0.1865215615506286 , \u001b[34mval: 0.2764849891137345 \u001b[0m, avg_train: 0.24913027704508242, avg_val: 0.2899893967915161 \n",
            "500106003: train: 0.2083387276068537 , \u001b[34mval: 0.22214283323579936\u001b[0m, avg_train: 0.24848279213336452, avg_val: 0.2889124672112666 \n",
            "500106004: train: 0.3023779469492505 , \u001b[34mval: 0.3504050171932726 \u001b[0m, avg_train: 0.24932490392736276, avg_val: 0.28987328830473547\n",
            "500119043: train: 0.11328934995045356, \u001b[34mval: 0.1645132567988495 \u001b[0m, avg_train: 0.24723204925079492, avg_val: 0.2879446724354141 \n",
            "500119044: train: 0.22699207781144914, \u001b[34mval: 0.28466499930302425\u001b[0m, avg_train: 0.24692538301686545, avg_val: 0.28789498041825673\n",
            "500119045: train: 0.18593571134384296, \u001b[34mval: 0.33978041892725436\u001b[0m, avg_train: 0.24601508940980538, avg_val: 0.28866938994824176\n",
            "500119046: train: 0.17591869682976233, \u001b[34mval: 0.23885179748701127\u001b[0m, avg_train: 0.24498426010715768, avg_val: 0.2879367782944002 \n",
            "500119047: train: 0.18842029948411948, \u001b[34mval: 0.26121102163442383\u001b[0m, avg_train: 0.24416449256189623, avg_val: 0.28754944848773384\n",
            "500119048: train: 0.18117136792772953, \u001b[34mval: 0.2120819910502669 \u001b[0m, avg_train: 0.24326459078140814, avg_val: 0.28647134195291285\n",
            "500119049: train: 0.11966315872489432, \u001b[34mval: 0.15139409655363315\u001b[0m, avg_train: 0.24152372554117552, avg_val: 0.2845688455388385 \n",
            "500119050: train: 0.1939721326195931 , \u001b[34mval: 0.2786430316993274 \u001b[0m, avg_train: 0.24086328675059798, avg_val: 0.2844865425688453 \n",
            "500119051: train: 0.11543977343936253, \u001b[34mval: 0.19665473309360051\u001b[0m, avg_train: 0.239145156431266  , avg_val: 0.28328336709658164\n",
            "500119052: train: 0.23245666257668426, \u001b[34mval: 0.27936722876159537\u001b[0m, avg_train: 0.23905477137917705, avg_val: 0.28323044630827104\n",
            "500119053: train: 0.2253102659475825 , \u001b[34mval: 0.28640380549976496\u001b[0m, avg_train: 0.23887151130675577, avg_val: 0.28327275776415767\n",
            "500119054: train: 0.16750011552496774, \u001b[34mval: 0.2015901961304142 \u001b[0m, avg_train: 0.23793241399383747, avg_val: 0.28219798721634526\n",
            "500119055: train: 0.3170903648365307 , \u001b[34mval: 0.30826583155161463\u001b[0m, avg_train: 0.23896043932945688, avg_val: 0.2825365306492708 \n",
            "500119056: train: 0.24559294030286224, \u001b[34mval: 0.2500096351409687 \u001b[0m, avg_train: 0.2390454713932185 , avg_val: 0.28211951916839517\n",
            "500119057: train: 0.22948085928009412, \u001b[34mval: 0.24630703934999867\u001b[0m, avg_train: 0.23892440035381188, avg_val: 0.2816661966390484 \n",
            "500119058: train: 0.22753613175120463, \u001b[34mval: 0.3542695843742821 \u001b[0m, avg_train: 0.23878204699627928, avg_val: 0.28257373898573884\n",
            "500119059: train: 0.0999949045975016 , \u001b[34mval: 0.0752034916416354 \u001b[0m, avg_train: 0.23706862548518326, avg_val: 0.2800136124753178 \n",
            "500119060: train: 0.248796437874324  , \u001b[34mval: 0.2809985867176203 \u001b[0m, avg_train: 0.23721164758748986, avg_val: 0.28002562435632145\n",
            "500119061: train: 0.21660043840585935, \u001b[34mval: 0.2617049424184574 \u001b[0m, avg_train: 0.23696331976602444, avg_val: 0.27980489324863633\n",
            "500119062: train: 0.15721961078187385, \u001b[34mval: 0.1743082434771334 \u001b[0m, avg_train: 0.2360139898971655 , avg_val: 0.27854898075135653\n",
            "500119063: train: 0.1462705923955382 , \u001b[34mval: 0.13620541613901327\u001b[0m, avg_train: 0.23495818522067574, avg_val: 0.2768743505794466 \n",
            "500119064: train: 0.14000682395656058, \u001b[34mval: 0.165604856707505  \u001b[0m, avg_train: 0.2338540996245814 , avg_val: 0.27558051925535426\n",
            "500119065: train: 0.1959710574114174 , \u001b[34mval: 0.2527254147656734 \u001b[0m, avg_train: 0.2334186623577634 , avg_val: 0.27531781690489815\n",
            "500119066: train: 0.18796803498431786, \u001b[34mval: 0.2542433282832888 \u001b[0m, avg_train: 0.23290217795579246, avg_val: 0.2750783340796526 \n",
            "500119067: train: 0.1258115767618064 , \u001b[34mval: 0.18553789985368624\u001b[0m, avg_train: 0.23169891277383753, avg_val: 0.2740722617849788 \n",
            "500119068: train: 0.13536639802492204, \u001b[34mval: 0.15390299342068714\u001b[0m, avg_train: 0.23062855149884956, avg_val: 0.2727370476920422 \n",
            "500119069: train: 0.20574224100782298, \u001b[34mval: 0.21210606082767616\u001b[0m, avg_train: 0.23035507555938772, avg_val: 0.2720707731111151 \n",
            "500119070: train: 0.34424601724945886, \u001b[34mval: 0.265470144028841  \u001b[0m, avg_train: 0.2315930205777581 , avg_val: 0.27199902714282953\n",
            "500119071: train: 0.1590603797900285 , \u001b[34mval: 0.25175607212803336\u001b[0m, avg_train: 0.23081309970907282, avg_val: 0.2717813609598747 \n",
            "500119072: train: 0.20148672561389688, \u001b[34mval: 0.21816205858024543\u001b[0m, avg_train: 0.23050111700593265, avg_val: 0.27121094284945313\n",
            "500119074: train: 0.19215785385886455, \u001b[34mval: 0.21675555437093005\u001b[0m, avg_train: 0.23009750370964774, avg_val: 0.2706377282338897 \n",
            "500119075: train: 0.1596999636451549 , \u001b[34mval: 0.21627494149943033\u001b[0m, avg_train: 0.22936419600064262, avg_val: 0.27007144920540577\n",
            "500119076: train: 0.14042984063733419, \u001b[34mval: 0.17326508078245936\u001b[0m, avg_train: 0.2284473469762786 , avg_val: 0.2690734454072311 \n",
            "500119077: train: 0.2278516103773875 , \u001b[34mval: 0.28286166062328433\u001b[0m, avg_train: 0.228441268031392  , avg_val: 0.26921414148086426\n",
            "500119078: train: 0.40481723523102847, \u001b[34mval: 0.3337591230447566 \u001b[0m, avg_train: 0.23022284345765096, avg_val: 0.2698661109916107 \n",
            "500119079: train: 0.40549675974825244, \u001b[34mval: 0.361740358468579  \u001b[0m, avg_train: 0.23197558262055698, avg_val: 0.27078485346638037\n",
            "500119080: train: 0.21298902851682458, \u001b[34mval: 0.19502936533230558\u001b[0m, avg_train: 0.23178759693636158, avg_val: 0.2700347991284192 \n",
            "500119081: train: 0.23176453933330474, \u001b[34mval: 0.308569661665601  \u001b[0m, avg_train: 0.23178737088142967, avg_val: 0.2704125918983916 \n",
            "500119082: train: 0.3715899321084859 , \u001b[34mval: 0.2848318616863956 \u001b[0m, avg_train: 0.2331446773011098 , avg_val: 0.2705525848089548 \n",
            "500119083: train: 0.2482873247079375 , \u001b[34mval: 0.23727708483461007\u001b[0m, avg_train: 0.2332902796800216 , avg_val: 0.2702326280784322 \n",
            "500119084: train: 0.20049300781222248, \u001b[34mval: 0.2682957214575821 \u001b[0m, avg_train: 0.23297792470985212, avg_val: 0.27021418134870984\n",
            "500119085: train: 0.196767221939978  , \u001b[34mval: 0.2624488012622891 \u001b[0m, avg_train: 0.23263631430636275, avg_val: 0.27014092304600773\n",
            "500119086: train: 0.1960768803520105 , \u001b[34mval: 0.2000969217594948 \u001b[0m, avg_train: 0.23229463735351832, avg_val: 0.26948630621155434\n",
            "500119087: train: 0.19789593212154036, \u001b[34mval: 0.23441363398782353\u001b[0m, avg_train: 0.23197613082359259, avg_val: 0.2691615592465198 \n",
            "500119088: train: 0.22273347509715063, \u001b[34mval: 0.2715985034007692 \u001b[0m, avg_train: 0.231891335816928  , avg_val: 0.26918391653233864\n",
            "500119089: train: 0.1554371858018211 , \u001b[34mval: 0.20297713647270135\u001b[0m, avg_train: 0.23119629808951794, avg_val: 0.26858203671361464\n",
            "500119090: train: 0.23086361777850944, \u001b[34mval: 0.2633797109557871 \u001b[0m, avg_train: 0.23119330096959895, avg_val: 0.26853516891399454\n",
            "500119091: train: 0.23803199670111938, \u001b[34mval: 0.21672466857185718\u001b[0m, avg_train: 0.2312543607529161 , avg_val: 0.26807257516093974\n",
            "final: train: 0.2312543607529161, val: 0.26807257516093974\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.26807257516093974"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run(num_leaves=31, learning_rate=0.05, feature_fraction=0.9, num_round=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
