{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HEmT9VhRK_dF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from time import localtime, strftime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wfCq6h0SA49",
        "outputId": "c389dc8c-65c0-4b58-db81-ba38adb63848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predict_stns: ['500101001', '500101002', '500101003', '500101004', '500101005', '500101006', '500101007', '500101008', '500101009', '500101010', '500101013', '500101014', '500101015', '500101018', '500101019', '500101020', '500101021', '500101022', '500101023', '500101024', '500101025', '500101026', '500101027', '500101028', '500101029', '500101030', '500101031', '500101032', '500101033', '500101034', '500101035', '500101036', '500101037', '500101038', '500101039', '500101040', '500101041', '500101042', '500101091', '500101092', '500101093', '500101094', '500101114', '500101115', '500101123', '500101166', '500101175', '500101176', '500101181', '500101184', '500101185', '500101188', '500101189', '500101190', '500101191', '500101193', '500101199', '500101209', '500101216', '500101219', '500105066', '500106002', '500106003', '500106004', '500119043', '500119044', '500119045', '500119046', '500119047', '500119048', '500119049', '500119050', '500119051', '500119052', '500119053', '500119054', '500119055', '500119056', '500119057', '500119058', '500119059', '500119060', '500119061', '500119062', '500119063', '500119064', '500119065', '500119066', '500119067', '500119068', '500119069', '500119070', '500119071', '500119072', '500119074', '500119075', '500119076', '500119077', '500119078', '500119079', '500119080', '500119081', '500119082', '500119083', '500119084', '500119085', '500119086', '500119087', '500119088', '500119089', '500119090', '500119091']\n"
          ]
        }
      ],
      "source": [
        "with open(\"./data_sno_test_set.txt\", \"r\") as f:\n",
        "    predict_stns = f.read().split()\n",
        "    predict_stns.sort()\n",
        "print(\"predict_stns:\", predict_stns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BsdGB3ifOg2O"
      },
      "outputs": [],
      "source": [
        "def Err_func(b_predict, b_truth, total):\n",
        "    return 3 * abs(b_predict - b_truth) / total * ( abs((3 * b_truth - total)/(3 *total)) + abs((3 * b_truth - 2 * total)/(3 * total)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5tC5e_rPOkFh"
      },
      "outputs": [],
      "source": [
        "def val(predic_y, y, total):\n",
        "  err = 0\n",
        "  for i in range(len(y)):\n",
        "    err += Err_func(float(predic_y[i]), y[i], total)\n",
        "\n",
        "  return err / len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mJscZbxSqTVP"
      },
      "outputs": [],
      "source": [
        "def Load_stn_tot():\n",
        "  with open(\"./data_stn_tot.json\", 'r') as f:\n",
        "    stn_tot = json.load(f)\n",
        "  return dict(stn_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1_ZwZr6C_fZS"
      },
      "outputs": [],
      "source": [
        "def read_data(stn, mode):\n",
        "  data = []\n",
        "  x = []\n",
        "  y = []\n",
        "  path = f\"./data/{stn}_{mode}.txt\"\n",
        "\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      tmp_list = line.split()\n",
        "      for i in range(len(tmp_list)):\n",
        "        if i not in [0, 1, 2]:\n",
        "          tmp_list[i] = float(tmp_list[i])\n",
        "      # if tmp_list[1] in week_list:\n",
        "      min = int(tmp_list[2][:2]) * 60 + int(tmp_list[2][3:])\n",
        "      weekday = int(tmp_list[4])\n",
        "      all_min = 1440 * (weekday - 1) + min\n",
        "      if tmp_list[4] == 5 and min > 1440 - 60 * 6:\n",
        "        tmp_list[5] = 0\n",
        "\n",
        "      def sin_a(a, b):\n",
        "        return np.sin(a * 2 * np.pi / b)\n",
        "      def cos_a(a, b):\n",
        "        return np.cos(a * 2 * np.pi / b)\n",
        "      k = 1440\n",
        "      x_input = []\n",
        "      rain = float(tmp_list[7])\n",
        "      # for i in range(1, 7):\n",
        "      #   x_input.append(sin_a(min, k * i))\n",
        "      #   x_input.append(cos_a(min, k * i))\n",
        "      x_input = [sin_a(min, k), cos_a(min, k), sin_a(all_min, k * 7), cos_a(all_min, k * 7)] + tmp_list[5:8]\n",
        "      y_label = int(tmp_list[8])\n",
        "      x.append(list(x_input))\n",
        "      y.append(y_label)\n",
        "      \n",
        "      frac = y_label/ tmp_list[3]\n",
        "      N = 10\n",
        "      if mode == 'train':\n",
        "        for i in range(int(N * 3 * ( abs(frac - 1/3) + abs(frac - 2/3))) - (N - 1)):\n",
        "          x.append(list(x_input))\n",
        "          y.append(y_label)\n",
        "          if weekday in [6, 7]:\n",
        "            for i in range(1):\n",
        "              x.append(list(x_input))\n",
        "              y.append(y_label)\n",
        "          if rain != 0:\n",
        "            for i in range(2):\n",
        "              x.append(list(x_input))\n",
        "              y.append(y_label)\n",
        "\n",
        "          # if min <= 60 * 7 or min >= 1440 - 60 * 2:\n",
        "          #   x.append(list(x_input))\n",
        "          #   y.append(int(tmp_list[10]))\n",
        "        # if min <= 60 * 7 or min >= 1440 - 60 * 2:\n",
        "        #     x.append(list(x_input))\n",
        "        #     y.append(int(tmp_list[10]))\n",
        "          \n",
        "      data.append(tmp_list)\n",
        "      \n",
        "  # print(\"data:\", data)\n",
        "  # print(\"x_train:\", x)\n",
        "  # print(\"y_train:\", y)\n",
        "  data = np.array(data)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  scaler = StandardScaler()\n",
        "  # x = scaler.fit_transform(x)\n",
        "  # y = scaler.transform(y)\n",
        "  return data, x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f99RZ62fAP6Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500101001: train: 0.19338767687897376, \u001b[34mval: 0.2241852264131448 \u001b[0m, avg_train: 0.19338767687897376, avg_val: 0.2241852264131448 \n",
            "500101002: train: 0.16272887280448886, \u001b[34mval: 0.25908145497401575\u001b[0m, avg_train: 0.1780582748417313 , avg_val: 0.24163334069358028\n",
            "500101003: train: 0.27623464887107035, \u001b[34mval: 0.3946498199975066 \u001b[0m, avg_train: 0.21078373285151097, avg_val: 0.29263883379488903\n",
            "500101004: train: 0.36455005127800755, \u001b[34mval: 0.37496492364789547\u001b[0m, avg_train: 0.24922531245813512, avg_val: 0.31322035625814065\n",
            "500101005: train: 0.27005884343940817, \u001b[34mval: 0.22216058234558378\u001b[0m, avg_train: 0.25339201865438976, avg_val: 0.29500840147562923\n",
            "500101006: train: 0.2645270870194021 , \u001b[34mval: 0.16852325934295725\u001b[0m, avg_train: 0.2552478633818918 , avg_val: 0.27392754445351725\n",
            "500101007: train: 0.2522307797449429 , \u001b[34mval: 0.1675967801293903 \u001b[0m, avg_train: 0.25481685143375626, avg_val: 0.2587374352643563 \n",
            "500101008: train: 0.39864173126892793, \u001b[34mval: 0.513941131749709  \u001b[0m, avg_train: 0.27279496141315274, avg_val: 0.2906378973250254 \n",
            "500101009: train: 0.40436525043989724, \u001b[34mval: 0.3714572535196973 \u001b[0m, avg_train: 0.2874138824161243 , avg_val: 0.2996178257911    \n",
            "500101010: train: 0.37228207709191435, \u001b[34mval: 0.31670536327389587\u001b[0m, avg_train: 0.2959007018837033 , avg_val: 0.3013265795393796 \n",
            "500101013: train: 0.44511192143035355, \u001b[34mval: 0.323343871770073  \u001b[0m, avg_train: 0.3094653582061261 , avg_val: 0.3033281515603517 \n",
            "500101014: train: 0.4420685545774828 , \u001b[34mval: 0.4720449264223412 \u001b[0m, avg_train: 0.32051562457040583, avg_val: 0.31738788279885083\n",
            "500101015: train: 0.2761296758920646 , \u001b[34mval: 0.3617099345711082 \u001b[0m, avg_train: 0.317101320825918  , avg_val: 0.32079727139671677\n",
            "500101018: train: 0.5397060528524066 , \u001b[34mval: 0.5099602598556241 \u001b[0m, avg_train: 0.3330016588278101 , avg_val: 0.3343089134294959 \n",
            "500101019: train: 0.3212820702876372 , \u001b[34mval: 0.24255633981655253\u001b[0m, avg_train: 0.3322203529251319 , avg_val: 0.32819207518863297\n",
            "500101020: train: 0.0                , \u001b[34mval: 0.0                \u001b[0m, avg_train: 0.31145658086731115, avg_val: 0.3076800704893434 \n",
            "500101021: train: 0.28938021497427535, \u001b[34mval: 0.2675686162077474 \u001b[0m, avg_train: 0.31015797110889726, avg_val: 0.30532057317866135\n",
            "500101022: train: 0.1385941301605028 , \u001b[34mval: 0.20574653821876226\u001b[0m, avg_train: 0.30062664661176425, avg_val: 0.29978868234755585\n",
            "500101023: train: 0.23448229582355307, \u001b[34mval: 0.20146824547177167\u001b[0m, avg_train: 0.2971453649913321 , avg_val: 0.29461392251198826\n",
            "500101024: train: 0.11474873872212119, \u001b[34mval: 0.231876772815757  \u001b[0m, avg_train: 0.28802553367787154, avg_val: 0.2914770650271767 \n",
            "500101025: train: 0.09870068013951244, \u001b[34mval: 0.14057969042905252\u001b[0m, avg_train: 0.27901006446175924, avg_val: 0.2842914757605993 \n",
            "500101026: train: 0.32673746768268563, \u001b[34mval: 0.37187941724081625\u001b[0m, avg_train: 0.28117949188089225, avg_val: 0.2882727458278819 \n",
            "500101027: train: 0.24351988052958667, \u001b[34mval: 0.5492438501904348 \u001b[0m, avg_train: 0.2795421174743138 , avg_val: 0.29961931558277555\n",
            "500101028: train: 0.2947667215284234 , \u001b[34mval: 0.29949990005417576\u001b[0m, avg_train: 0.28017647597656836, avg_val: 0.29961433993575054\n",
            "500101029: train: 0.202632516639159  , \u001b[34mval: 0.3332607280324656 \u001b[0m, avg_train: 0.277074717603072  , avg_val: 0.30096019545961916\n",
            "500101030: train: 0.16134874546736205, \u001b[34mval: 0.1926108167041789 \u001b[0m, avg_train: 0.2726237186747755 , avg_val: 0.296792911661333  \n",
            "500101031: train: 0.2684054830559511 , \u001b[34mval: 0.27800022919429995\u001b[0m, avg_train: 0.2724674877259301 , avg_val: 0.2960968863847762 \n",
            "500101032: train: 0.10936657462346332, \u001b[34mval: 0.23364031979741356\u001b[0m, avg_train: 0.26664245511512774, avg_val: 0.29386629472094183\n",
            "500101033: train: 0.13254526385924362, \u001b[34mval: 0.19504427875591515\u001b[0m, avg_train: 0.2620184140373386 , avg_val: 0.2904586389980099 \n",
            "500101034: train: 0.14476910145900296, \u001b[34mval: 0.19793509189752942\u001b[0m, avg_train: 0.25811010361806075, avg_val: 0.2873745207613272 \n",
            "500101035: train: 0.1452608419935377 , \u001b[34mval: 0.18718994924736435\u001b[0m, avg_train: 0.25446980485597936, avg_val: 0.28414276038990904\n",
            "500101036: train: 0.13093089205212774, \u001b[34mval: 0.13601405248167822\u001b[0m, avg_train: 0.250609213830859  , avg_val: 0.27951373826777687\n",
            "500101037: train: 0.2236194940941015 , \u001b[34mval: 0.24089851202172088\u001b[0m, avg_train: 0.24979134353580573, avg_val: 0.27834357989668423\n",
            "500101038: train: 0.14657586054893676, \u001b[34mval: 0.1503140898270879 \u001b[0m, avg_train: 0.24675559403619196, avg_val: 0.2745780066593432 \n",
            "500101039: train: 0.265600651475487  , \u001b[34mval: 0.18886012539752398\u001b[0m, avg_train: 0.24729402424874328, avg_val: 0.2721289243375769 \n",
            "500101040: train: 0.33071775429808126, \u001b[34mval: 0.23489002708259143\u001b[0m, avg_train: 0.24961135008344712, avg_val: 0.27109451052493844\n",
            "500101041: train: 0.2570537953978149 , \u001b[34mval: 0.13242964555528206\u001b[0m, avg_train: 0.2498124972541057 , avg_val: 0.26734681147170447\n",
            "500101042: train: 0.19628463160200987, \u001b[34mval: 0.31286490014614865\u001b[0m, avg_train: 0.24840386921062949, avg_val: 0.26854465591050564\n",
            "500101091: train: 0.2503719459320099 , \u001b[34mval: 0.26217767275154275\u001b[0m, avg_train: 0.2484543327163059 , avg_val: 0.2683813999320707 \n",
            "500101092: train: 0.23903291013455039, \u001b[34mval: 0.27458504579633697\u001b[0m, avg_train: 0.24821879715176204, avg_val: 0.2685364910786774 \n",
            "500101093: train: 0.24033718845888713, \u001b[34mval: 0.15146069484912847\u001b[0m, avg_train: 0.24802656279339924, avg_val: 0.2656809838535664 \n",
            "500101094: train: 0.25016903332434254, \u001b[34mval: 0.32787577903820203\u001b[0m, avg_train: 0.24807757399651692, avg_val: 0.26716181231034347\n",
            "500101114: train: 0.340632126710911  , \u001b[34mval: 0.3675560929940626 \u001b[0m, avg_train: 0.25023000545499124, avg_val: 0.26949656302391833\n",
            "500101115: train: 0.21137331543550705, \u001b[34mval: 0.2946798788937283 \u001b[0m, avg_train: 0.2493468988636393 , avg_val: 0.27006891111186854\n",
            "500101123: train: 0.14437902264862348, \u001b[34mval: 0.188697116178406  \u001b[0m, avg_train: 0.2470142793921945 , avg_val: 0.26826064900223606\n",
            "500101166: train: 0.13580076104994857, \u001b[34mval: 0.18270255447305964\u001b[0m, avg_train: 0.24459659421084132, avg_val: 0.26640069042551484\n",
            "500101175: train: 0.28882014506013015, \u001b[34mval: 0.2000619052155909 \u001b[0m, avg_train: 0.245537520824656  , avg_val: 0.2649892269104101 \n",
            "500101176: train: 0.22782267825841104, \u001b[34mval: 0.14828649283968506\u001b[0m, avg_train: 0.24516846160452588, avg_val: 0.2625579199506033 \n",
            "500101181: train: 0.2073733332287763 , \u001b[34mval: 0.3667882372865649 \u001b[0m, avg_train: 0.24439713245400038, avg_val: 0.26468506928399027\n",
            "500101184: train: 0.28589989622000395, \u001b[34mval: 0.27567876751828696\u001b[0m, avg_train: 0.24522718772932045, avg_val: 0.2649049432486762 \n",
            "500101185: train: 0.37689102356634696, \u001b[34mval: 0.4214975861985709 \u001b[0m, avg_train: 0.24780883156926214, avg_val: 0.2679753872280859 \n",
            "500101188: train: 0.1676358467404679 , \u001b[34mval: 0.2308631385540385 \u001b[0m, avg_train: 0.24626704339947766, avg_val: 0.2672616901382004 \n",
            "500101189: train: 0.4478348838305304 , \u001b[34mval: 0.4739825241987154 \u001b[0m, avg_train: 0.2500702102000636 , avg_val: 0.2711620832336818 \n",
            "500101190: train: 0.20501469821664273, \u001b[34mval: 0.36132109776480786\u001b[0m, avg_train: 0.24923584886703726, avg_val: 0.27283169461388784\n",
            "500101191: train: 0.1684393994704888 , \u001b[34mval: 0.19227891985239745\u001b[0m, avg_train: 0.2477668225143727 , avg_val: 0.27136709870913345\n",
            "500101193: train: 0.1382823597876689 , \u001b[34mval: 0.319742177445143  \u001b[0m, avg_train: 0.24581174282282442, avg_val: 0.2722309394008479 \n",
            "500101199: train: 0.30252768697299365, \u001b[34mval: 0.338373761977983  \u001b[0m, avg_train: 0.24680675938686247, avg_val: 0.273391339796938  \n",
            "500101209: train: 0.11920396422382283, \u001b[34mval: 0.1719661166664523 \u001b[0m, avg_train: 0.24460671119439628, avg_val: 0.27164262905330894\n",
            "500101216: train: 0.2845204336317005 , \u001b[34mval: 0.2962829696742582 \u001b[0m, avg_train: 0.24528321496452007, avg_val: 0.27206026194518945\n",
            "500101219: train: 0.4272045602522777 , \u001b[34mval: 0.37480752661563427\u001b[0m, avg_train: 0.2483152373859827 , avg_val: 0.2737727163563635 \n",
            "500105066: train: 0.30490446949022626, \u001b[34mval: 0.4760859276216359 \u001b[0m, avg_train: 0.24924292971556047, avg_val: 0.2770893263771057 \n",
            "500106002: train: 0.21186648219974696, \u001b[34mval: 0.1986546029505884 \u001b[0m, avg_train: 0.24864008378788607, avg_val: 0.275824250192807  \n",
            "500106003: train: 0.2038900532686755 , \u001b[34mval: 0.2548981737790068 \u001b[0m, avg_train: 0.24792976584313672, avg_val: 0.2754920902497308 \n",
            "500106004: train: 0.29403013999132116, \u001b[34mval: 0.4020556478871237 \u001b[0m, avg_train: 0.2486500841892021 , avg_val: 0.2774696458378151 \n",
            "500119043: train: 0.11029508523176364, \u001b[34mval: 0.2339606328002651 \u001b[0m, avg_train: 0.24652154574370302, avg_val: 0.27680027640646815\n",
            "500119044: train: 0.2431547599837588 , \u001b[34mval: 0.2559730858637385 \u001b[0m, avg_train: 0.24647053383824932, avg_val: 0.27648471291339655\n",
            "500119045: train: 0.2343907270554177 , \u001b[34mval: 0.17996849396641493\u001b[0m, avg_train: 0.24629023821462495, avg_val: 0.27504417233209827\n",
            "500119046: train: 0.1739815861096082 , \u001b[34mval: 0.37634597325466   \u001b[0m, avg_train: 0.24522687568366883, avg_val: 0.27653390469860656\n",
            "500119047: train: 0.19261297789757403, \u001b[34mval: 0.24787798859075796\u001b[0m, avg_train: 0.24446435542589934, avg_val: 0.2761186015666087 \n",
            "500119048: train: 0.1541903247510478 , \u001b[34mval: 0.2408685914762388 \u001b[0m, avg_train: 0.24317472641625862, avg_val: 0.2756150299938892 \n",
            "500119049: train: 0.11644208453506191, \u001b[34mval: 0.22629143989964778\u001b[0m, avg_train: 0.24138975962919954, avg_val: 0.27492033154185763\n",
            "500119050: train: 0.18986123225051202, \u001b[34mval: 0.213664945030122  \u001b[0m, avg_train: 0.24067408563782886, avg_val: 0.27406956228475016\n",
            "500119051: train: 0.11630819362505954, \u001b[34mval: 0.16103143979264575\u001b[0m, avg_train: 0.23897044328148956, avg_val: 0.27252109485335146\n",
            "500119052: train: 0.24649947240755624, \u001b[34mval: 0.29657785980213813\u001b[0m, avg_train: 0.2390721869183283 , avg_val: 0.2728461862715783 \n",
            "500119053: train: 0.23491212423351704, \u001b[34mval: 0.22811662251810197\u001b[0m, avg_train: 0.23901671941586414, avg_val: 0.2722497920881986 \n",
            "500119054: train: 0.144606043457543  , \u001b[34mval: 0.20615049276744501\u001b[0m, avg_train: 0.23777447367957044, avg_val: 0.2713800644655571 \n",
            "500119055: train: 0.31651884482813053, \u001b[34mval: 0.4146970313602262 \u001b[0m, avg_train: 0.23879712785033097, avg_val: 0.2732413237758775 \n",
            "500119056: train: 0.25645775721802117, \u001b[34mval: 0.24006744635316296\u001b[0m, avg_train: 0.2390235461755578 , avg_val: 0.27281601765507346\n",
            "500119057: train: 0.24283879590658597, \u001b[34mval: 0.28496887359298584\u001b[0m, avg_train: 0.23907184047595056, avg_val: 0.2729698512745407 \n",
            "500119058: train: 0.23246264545061793, \u001b[34mval: 0.41564278342363803\u001b[0m, avg_train: 0.2389892255381339 , avg_val: 0.27475326292640445\n",
            "500119059: train: 0.08346408081317645, \u001b[34mval: 0.3289261180346266 \u001b[0m, avg_train: 0.23706916202301095, avg_val: 0.27542206360675286\n",
            "500119060: train: 0.24768581576089527, \u001b[34mval: 0.23364733750011896\u001b[0m, avg_train: 0.2371986334100583 , avg_val: 0.27491261572740366\n",
            "500119061: train: 0.23884851501003498, \u001b[34mval: 0.30423731526242787\u001b[0m, avg_train: 0.2372185115016243 , avg_val: 0.27526592536035577\n",
            "500119062: train: 0.15263260347201396, \u001b[34mval: 0.2506835397878374 \u001b[0m, avg_train: 0.2362115364060337 , avg_val: 0.27497327791306386\n",
            "500119063: train: 0.14699931598321128, \u001b[34mval: 0.20870362670407935\u001b[0m, avg_train: 0.23516198087164755, avg_val: 0.274193634957664  \n",
            "500119064: train: 0.1303559326914136 , \u001b[34mval: 0.14739173881321158\u001b[0m, avg_train: 0.23394330589280762, avg_val: 0.27271919430482155\n",
            "500119065: train: 0.22894204220613767, \u001b[34mval: 0.19212377082313442\u001b[0m, avg_train: 0.23388582010330566, avg_val: 0.2717928101268711 \n",
            "500119066: train: 0.1928555533875538 , \u001b[34mval: 0.18025364327913562\u001b[0m, avg_train: 0.23341956707244485, avg_val: 0.2707525923217833 \n",
            "500119067: train: 0.138175246935714  , \u001b[34mval: 0.12182654090766179\u001b[0m, avg_train: 0.23234940617203212, avg_val: 0.26907926590139986\n",
            "500119068: train: 0.13600739444838328, \u001b[34mval: 0.20981186845696081\u001b[0m, avg_train: 0.23127893937510272, avg_val: 0.2684207392631283 \n",
            "500119069: train: 0.18000225731309516, \u001b[34mval: 0.24236599117189364\u001b[0m, avg_train: 0.23071545935244328, avg_val: 0.26813442335003784\n",
            "500119070: train: 0.3237402346975479 , \u001b[34mval: 0.22240952026716293\u001b[0m, avg_train: 0.23172659821489008, avg_val: 0.2676374135339196 \n",
            "500119071: train: 0.16702317500909464, \u001b[34mval: 0.24101784725082986\u001b[0m, avg_train: 0.23103086248149446, avg_val: 0.26735118163840255\n",
            "500119072: train: 0.22439095669358478, \u001b[34mval: 0.24376283285303563\u001b[0m, avg_train: 0.23096022518587841, avg_val: 0.2671002417577072 \n",
            "500119074: train: 0.19340128769737316, \u001b[34mval: 0.235932985359183  \u001b[0m, avg_train: 0.2305648679491573 , avg_val: 0.26677216537456483\n",
            "500119075: train: 0.1629287642129609 , \u001b[34mval: 0.24640608326167546\u001b[0m, avg_train: 0.22986032520190525, avg_val: 0.2665600186858889 \n",
            "500119076: train: 0.1263009328857885 , \u001b[34mval: 0.26321574515870966\u001b[0m, avg_train: 0.22879270260070816, avg_val: 0.26652554163921693\n",
            "500119077: train: 0.2414163774325869 , \u001b[34mval: 0.24179122662664632\u001b[0m, avg_train: 0.22892151560919669, avg_val: 0.2662731506697009 \n",
            "500119078: train: 0.4063500180929848 , \u001b[34mval: 0.33064221921785836\u001b[0m, avg_train: 0.23071372270499255, avg_val: 0.26692334328129846\n",
            "500119079: train: 0.3973539860832136 , \u001b[34mval: 0.4157675414909505 \u001b[0m, avg_train: 0.23238012533877478, avg_val: 0.268411785263395  \n",
            "500119080: train: 0.21057690320168373, \u001b[34mval: 0.16913320577147486\u001b[0m, avg_train: 0.2321642518522689 , avg_val: 0.2674288290308017 \n",
            "500119081: train: 0.24104287767101595, \u001b[34mval: 0.2272541351337477 \u001b[0m, avg_train: 0.2322512972034331 , avg_val: 0.2670349594827914 \n",
            "500119082: train: 0.3036979337782938 , \u001b[34mval: 0.40970991151892455\u001b[0m, avg_train: 0.23294495386920847, avg_val: 0.26842015319188   \n",
            "500119083: train: 0.22822260192734295, \u001b[34mval: 0.22170697769899392\u001b[0m, avg_train: 0.23289954663899823, avg_val: 0.26797098804291   \n",
            "500119084: train: 0.17489113378512605, \u001b[34mval: 0.21426564521397065\u001b[0m, avg_train: 0.23234708556419945, avg_val: 0.26745950858739626\n",
            "500119085: train: 0.2051599554880094 , \u001b[34mval: 0.224037517968445  \u001b[0m, avg_train: 0.23209060320499011, avg_val: 0.26704986716646273\n",
            "500119086: train: 0.2139539390826681 , \u001b[34mval: 0.1700304803591775 \u001b[0m, avg_train: 0.23192110167113664, avg_val: 0.26614314392527316\n",
            "500119087: train: 0.1947966167372268 , \u001b[34mval: 0.2150701125275844 \u001b[0m, avg_train: 0.23157735644026708, avg_val: 0.26567024548640567\n",
            "500119088: train: 0.2404092537927871 , \u001b[34mval: 0.23360333822354315\u001b[0m, avg_train: 0.23165838302148287, avg_val: 0.2653760536766546 \n",
            "500119089: train: 0.16350825643352632, \u001b[34mval: 0.2192414975331805 \u001b[0m, avg_train: 0.23103883641613782, avg_val: 0.26495664862080487\n",
            "500119090: train: 0.22387069385757657, \u001b[34mval: 0.2627902151640754 \u001b[0m, avg_train: 0.2309742585552499 , avg_val: 0.26493713120227574\n",
            "500119091: train: 0.21337269108951898, \u001b[34mval: 0.29913429548058684\u001b[0m, avg_train: 0.23081710170287728, avg_val: 0.26524246302618926\n",
            "final: train: 0.23081710170287728, val: 0.26524246302618926\n"
          ]
        }
      ],
      "source": [
        "\n",
        "all_val_err = 0\n",
        "all_train_err = 0\n",
        "count = 0\n",
        "stn_tot = Load_stn_tot()\n",
        "val_json = {}\n",
        "\n",
        "predict_file = open(f\"./lightGBM_predict_{strftime('%m%d-%H-%M-%S', localtime())}.csv\", 'w')\n",
        "predict_file.write(\"id,sbi\\n\")\n",
        "\n",
        "predict_log_file = open(f\"./lightGBM_predict_log_{strftime('%m%d-%H-%M-%S', localtime())}.txt\", \"w\")\n",
        "\n",
        "# predict_stns = ['500101001']\n",
        "for stn in predict_stns:\n",
        "  count += 1\n",
        "  data_train, x_train, y_train = read_data(stn, 'train')\n",
        "  data_val, x_val, y_val = read_data(stn, 'val')\n",
        "  data_test, x_test, y_test = read_data(stn, 'test')\n",
        "\n",
        "  train_data = lgb.Dataset(x_train, label=y_train)\n",
        "  val_data = lgb.Dataset(x_val, label=y_val, reference=train_data)\n",
        "  params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'verbose' : -1\n",
        "  }\n",
        "\n",
        "  # Train the model\n",
        "  num_round = 100\n",
        "  model = lgb.train(params, train_data, num_round, valid_sets=[val_data])\n",
        "  pre_train = model.predict(x_train)\n",
        "\n",
        "  pre_val = model.predict(x_val)\n",
        "  train_err = val(pre_train, y_train, int(stn_tot[stn]))\n",
        "  val_err = val(pre_val, y_val, int(stn_tot[stn]))\n",
        "  all_train_err += train_err\n",
        "  all_val_err += val_err\n",
        "  \n",
        "  log_info = f\"{stn}: train: {train_err:<19}, \\033[34mval: {val_err:<19}\\033[0m, avg_train: {all_train_err / count:<19}, avg_val: {all_val_err/count:<19}\"\n",
        "  print(log_info, file=predict_log_file)\n",
        "  print(log_info)\n",
        "  \n",
        "  val_json[stn] = {}\n",
        "  val_json[stn]['val'] = val_err\n",
        "  val_json[stn]['train'] = train_err\n",
        "  \n",
        "  \n",
        "  # plt.figure(figsize=(80, 5), dpi=300)\n",
        "  # plt.plot(pre_train, label='pre_train', color='b')\n",
        "  # plt.plot(y_train, label='truth', color='darkorange')\n",
        "  # plt.legend()\n",
        "  # plt.show()\n",
        "  \n",
        "  # plt.figure(figsize=(80, 5), dpi=300)\n",
        "  # plt.plot(pre_val, label='pre_train', color='b')\n",
        "  # plt.plot(y_val, label='truth', color='darkorange')\n",
        "  # plt.legend()\n",
        "  # plt.show()\n",
        "  \n",
        "  pre_test = model.predict(x_test)\n",
        "  for i in range(len(data_test)):\n",
        "    if data_test[i][2][3:] in [\"00\", \"20\", \"40\"]:\n",
        "      pre_test[i] = pre_test[i] if pre_test[i] > 0 else 0\n",
        "      id = f'{data_test[i][1]}_{int(data_test[i][0])}_{data_test[i][2]}'\n",
        "      predict_file.write(f\"{id},{pre_test[i]}\\n\")\n",
        "      \n",
        "log_info = f\"final: train: {all_train_err / len(predict_stns)}, val: {all_val_err / len(predict_stns)}\"\n",
        "print(log_info, file=predict_log_file)\n",
        "print(log_info)\n",
        "\n",
        "predict_file.close()\n",
        "predict_log_file.close()\n",
        "with open(\"./val_lightGBM.json\", 'w') as f: \n",
        "  json.dump(val_json, f, indent=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
